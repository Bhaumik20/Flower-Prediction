{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('../DATA/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "virginica     50\n",
       "versicolor    50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df.drop('species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/500\n",
      "120/120 [==============================] - 1s 9ms/sample - loss: 1.0802 - accuracy: 0.3500 - val_loss: 1.0859 - val_accuracy: 0.2667\n",
      "Epoch 2/500\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 1.0774 - accuracy: 0.3500 - val_loss: 1.0836 - val_accuracy: 0.2667\n",
      "Epoch 3/500\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 1.0744 - accuracy: 0.3500 - val_loss: 1.0809 - val_accuracy: 0.2667\n",
      "Epoch 4/500\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 1.0714 - accuracy: 0.3500 - val_loss: 1.0781 - val_accuracy: 0.2667\n",
      "Epoch 5/500\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 1.0682 - accuracy: 0.3500 - val_loss: 1.0750 - val_accuracy: 0.2667\n",
      "Epoch 6/500\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 1.0648 - accuracy: 0.3500 - val_loss: 1.0718 - val_accuracy: 0.2667\n",
      "Epoch 7/500\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 1.0612 - accuracy: 0.3500 - val_loss: 1.0684 - val_accuracy: 0.2667\n",
      "Epoch 8/500\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 1.0576 - accuracy: 0.3500 - val_loss: 1.0648 - val_accuracy: 0.2667\n",
      "Epoch 9/500\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 1.0540 - accuracy: 0.3500 - val_loss: 1.0611 - val_accuracy: 0.2667\n",
      "Epoch 10/500\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 1.0498 - accuracy: 0.3500 - val_loss: 1.0571 - val_accuracy: 0.2667\n",
      "Epoch 11/500\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 1.0453 - accuracy: 0.3500 - val_loss: 1.0530 - val_accuracy: 0.2667\n",
      "Epoch 12/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 1.0406 - accuracy: 0.3500 - val_loss: 1.0491 - val_accuracy: 0.2667\n",
      "Epoch 13/500\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 1.0362 - accuracy: 0.3500 - val_loss: 1.0449 - val_accuracy: 0.2667\n",
      "Epoch 14/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0310 - accuracy: 0.3500 - val_loss: 1.0405 - val_accuracy: 0.2667\n",
      "Epoch 15/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 1.0262 - accuracy: 0.3500 - val_loss: 1.0361 - val_accuracy: 0.2667\n",
      "Epoch 16/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 1.0209 - accuracy: 0.3500 - val_loss: 1.0316 - val_accuracy: 0.2667\n",
      "Epoch 17/500\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 1.0156 - accuracy: 0.3500 - val_loss: 1.0272 - val_accuracy: 0.2667\n",
      "Epoch 18/500\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 1.0106 - accuracy: 0.3500 - val_loss: 1.0231 - val_accuracy: 0.2667\n",
      "Epoch 19/500\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 1.0048 - accuracy: 0.3500 - val_loss: 1.0191 - val_accuracy: 0.3000\n",
      "Epoch 20/500\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.9993 - accuracy: 0.3500 - val_loss: 1.0150 - val_accuracy: 0.3000\n",
      "Epoch 21/500\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.9940 - accuracy: 0.3500 - val_loss: 1.0109 - val_accuracy: 0.3000\n",
      "Epoch 22/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.9886 - accuracy: 0.3500 - val_loss: 1.0068 - val_accuracy: 0.3000\n",
      "Epoch 23/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.9833 - accuracy: 0.3500 - val_loss: 1.0028 - val_accuracy: 0.3000\n",
      "Epoch 24/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.9779 - accuracy: 0.3500 - val_loss: 0.9987 - val_accuracy: 0.3000\n",
      "Epoch 25/500\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.9728 - accuracy: 0.3500 - val_loss: 0.9948 - val_accuracy: 0.3000\n",
      "Epoch 26/500\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.9677 - accuracy: 0.3583 - val_loss: 0.9909 - val_accuracy: 0.3000\n",
      "Epoch 27/500\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.9624 - accuracy: 0.3667 - val_loss: 0.9869 - val_accuracy: 0.3000\n",
      "Epoch 28/500\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.9574 - accuracy: 0.3667 - val_loss: 0.9828 - val_accuracy: 0.3000\n",
      "Epoch 29/500\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.9526 - accuracy: 0.3833 - val_loss: 0.9790 - val_accuracy: 0.3333\n",
      "Epoch 30/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.9481 - accuracy: 0.3833 - val_loss: 0.9754 - val_accuracy: 0.3667\n",
      "Epoch 31/500\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.9436 - accuracy: 0.3917 - val_loss: 0.9718 - val_accuracy: 0.3667\n",
      "Epoch 32/500\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.9394 - accuracy: 0.4167 - val_loss: 0.9683 - val_accuracy: 0.3667\n",
      "Epoch 33/500\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.9349 - accuracy: 0.4333 - val_loss: 0.9647 - val_accuracy: 0.3667\n",
      "Epoch 34/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.9309 - accuracy: 0.4500 - val_loss: 0.9615 - val_accuracy: 0.3667\n",
      "Epoch 35/500\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.9268 - accuracy: 0.4583 - val_loss: 0.9584 - val_accuracy: 0.4000\n",
      "Epoch 36/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.9229 - accuracy: 0.4833 - val_loss: 0.9552 - val_accuracy: 0.4333\n",
      "Epoch 37/500\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.9188 - accuracy: 0.5500 - val_loss: 0.9519 - val_accuracy: 0.4333\n",
      "Epoch 38/500\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.9149 - accuracy: 0.5917 - val_loss: 0.9487 - val_accuracy: 0.4667\n",
      "Epoch 39/500\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.9112 - accuracy: 0.6000 - val_loss: 0.9459 - val_accuracy: 0.4667\n",
      "Epoch 40/500\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.9074 - accuracy: 0.6083 - val_loss: 0.9430 - val_accuracy: 0.4667\n",
      "Epoch 41/500\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.9037 - accuracy: 0.6083 - val_loss: 0.9401 - val_accuracy: 0.5333\n",
      "Epoch 42/500\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.9000 - accuracy: 0.6250 - val_loss: 0.9371 - val_accuracy: 0.5333\n",
      "Epoch 43/500\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8962 - accuracy: 0.6417 - val_loss: 0.9340 - val_accuracy: 0.5333\n",
      "Epoch 44/500\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.8925 - accuracy: 0.6417 - val_loss: 0.9308 - val_accuracy: 0.5333\n",
      "Epoch 45/500\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.8890 - accuracy: 0.6417 - val_loss: 0.9277 - val_accuracy: 0.5333\n",
      "Epoch 46/500\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.8852 - accuracy: 0.6667 - val_loss: 0.9245 - val_accuracy: 0.5667\n",
      "Epoch 47/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.8818 - accuracy: 0.6667 - val_loss: 0.9215 - val_accuracy: 0.6000\n",
      "Epoch 48/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.8783 - accuracy: 0.6667 - val_loss: 0.9185 - val_accuracy: 0.6000\n",
      "Epoch 49/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.8746 - accuracy: 0.6667 - val_loss: 0.9153 - val_accuracy: 0.6000\n",
      "Epoch 50/500\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.8712 - accuracy: 0.6750 - val_loss: 0.9121 - val_accuracy: 0.6000\n",
      "Epoch 51/500\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.8677 - accuracy: 0.6833 - val_loss: 0.9091 - val_accuracy: 0.6000\n",
      "Epoch 52/500\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.8642 - accuracy: 0.6833 - val_loss: 0.9060 - val_accuracy: 0.6000\n",
      "Epoch 53/500\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.8608 - accuracy: 0.6833 - val_loss: 0.9028 - val_accuracy: 0.6000\n",
      "Epoch 54/500\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.8575 - accuracy: 0.6833 - val_loss: 0.8994 - val_accuracy: 0.6000\n",
      "Epoch 55/500\n",
      "120/120 [==============================] - 0s 171us/sample - loss: 0.8539 - accuracy: 0.6833 - val_loss: 0.8965 - val_accuracy: 0.6000\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 219us/sample - loss: 0.8506 - accuracy: 0.6833 - val_loss: 0.8936 - val_accuracy: 0.6000\n",
      "Epoch 57/500\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.8472 - accuracy: 0.6833 - val_loss: 0.8906 - val_accuracy: 0.6000\n",
      "Epoch 58/500\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.8441 - accuracy: 0.6833 - val_loss: 0.8879 - val_accuracy: 0.6000\n",
      "Epoch 59/500\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.8407 - accuracy: 0.6833 - val_loss: 0.8849 - val_accuracy: 0.6000\n",
      "Epoch 60/500\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.8373 - accuracy: 0.6833 - val_loss: 0.8819 - val_accuracy: 0.6000\n",
      "Epoch 61/500\n",
      "120/120 [==============================] - 0s 169us/sample - loss: 0.8340 - accuracy: 0.6833 - val_loss: 0.8785 - val_accuracy: 0.6000\n",
      "Epoch 62/500\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.8308 - accuracy: 0.6833 - val_loss: 0.8754 - val_accuracy: 0.6000\n",
      "Epoch 63/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.8279 - accuracy: 0.6833 - val_loss: 0.8719 - val_accuracy: 0.6000\n",
      "Epoch 64/500\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.8244 - accuracy: 0.6833 - val_loss: 0.8688 - val_accuracy: 0.6000\n",
      "Epoch 65/500\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.8213 - accuracy: 0.6833 - val_loss: 0.8659 - val_accuracy: 0.6000\n",
      "Epoch 66/500\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.8181 - accuracy: 0.6833 - val_loss: 0.8629 - val_accuracy: 0.6000\n",
      "Epoch 67/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.8150 - accuracy: 0.6833 - val_loss: 0.8598 - val_accuracy: 0.6000\n",
      "Epoch 68/500\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.8119 - accuracy: 0.6833 - val_loss: 0.8568 - val_accuracy: 0.6000\n",
      "Epoch 69/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.8089 - accuracy: 0.6833 - val_loss: 0.8540 - val_accuracy: 0.6000\n",
      "Epoch 70/500\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 0.8059 - accuracy: 0.6833 - val_loss: 0.8511 - val_accuracy: 0.6000\n",
      "Epoch 71/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.8029 - accuracy: 0.6833 - val_loss: 0.8484 - val_accuracy: 0.6000\n",
      "Epoch 72/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.8000 - accuracy: 0.6833 - val_loss: 0.8457 - val_accuracy: 0.6000\n",
      "Epoch 73/500\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.7970 - accuracy: 0.6833 - val_loss: 0.8430 - val_accuracy: 0.6000\n",
      "Epoch 74/500\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.7942 - accuracy: 0.6833 - val_loss: 0.8403 - val_accuracy: 0.6000\n",
      "Epoch 75/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.7914 - accuracy: 0.6833 - val_loss: 0.8376 - val_accuracy: 0.6000\n",
      "Epoch 76/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.7887 - accuracy: 0.6833 - val_loss: 0.8348 - val_accuracy: 0.6000\n",
      "Epoch 77/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.7858 - accuracy: 0.6833 - val_loss: 0.8319 - val_accuracy: 0.6000\n",
      "Epoch 78/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.7832 - accuracy: 0.6833 - val_loss: 0.8294 - val_accuracy: 0.6000\n",
      "Epoch 79/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.7804 - accuracy: 0.6833 - val_loss: 0.8266 - val_accuracy: 0.6000\n",
      "Epoch 80/500\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7777 - accuracy: 0.6833 - val_loss: 0.8239 - val_accuracy: 0.6000\n",
      "Epoch 81/500\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.7751 - accuracy: 0.6833 - val_loss: 0.8211 - val_accuracy: 0.6000\n",
      "Epoch 82/500\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.7725 - accuracy: 0.6833 - val_loss: 0.8185 - val_accuracy: 0.6000\n",
      "Epoch 83/500\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7699 - accuracy: 0.6833 - val_loss: 0.8159 - val_accuracy: 0.6000\n",
      "Epoch 84/500\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.7674 - accuracy: 0.6833 - val_loss: 0.8133 - val_accuracy: 0.6000\n",
      "Epoch 85/500\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.7649 - accuracy: 0.6833 - val_loss: 0.8109 - val_accuracy: 0.6000\n",
      "Epoch 86/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.7625 - accuracy: 0.6833 - val_loss: 0.8083 - val_accuracy: 0.6000\n",
      "Epoch 87/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.7600 - accuracy: 0.6833 - val_loss: 0.8058 - val_accuracy: 0.6000\n",
      "Epoch 88/500\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.7576 - accuracy: 0.6833 - val_loss: 0.8035 - val_accuracy: 0.6000\n",
      "Epoch 89/500\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.7553 - accuracy: 0.6833 - val_loss: 0.8011 - val_accuracy: 0.6000\n",
      "Epoch 90/500\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 0.7530 - accuracy: 0.6833 - val_loss: 0.7987 - val_accuracy: 0.6000\n",
      "Epoch 91/500\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.7507 - accuracy: 0.6833 - val_loss: 0.7967 - val_accuracy: 0.6000\n",
      "Epoch 92/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.7485 - accuracy: 0.6833 - val_loss: 0.7944 - val_accuracy: 0.6000\n",
      "Epoch 93/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.7462 - accuracy: 0.6833 - val_loss: 0.7924 - val_accuracy: 0.6000\n",
      "Epoch 94/500\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.7441 - accuracy: 0.6833 - val_loss: 0.7904 - val_accuracy: 0.6000\n",
      "Epoch 95/500\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.7418 - accuracy: 0.6833 - val_loss: 0.7880 - val_accuracy: 0.6000\n",
      "Epoch 96/500\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 0.7397 - accuracy: 0.6833 - val_loss: 0.7857 - val_accuracy: 0.6000\n",
      "Epoch 97/500\n",
      "120/120 [==============================] - 0s 178us/sample - loss: 0.7377 - accuracy: 0.6833 - val_loss: 0.7833 - val_accuracy: 0.6000\n",
      "Epoch 98/500\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7355 - accuracy: 0.6833 - val_loss: 0.7813 - val_accuracy: 0.6000\n",
      "Epoch 99/500\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 0.7334 - accuracy: 0.6833 - val_loss: 0.7791 - val_accuracy: 0.6000\n",
      "Epoch 100/500\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 0.7313 - accuracy: 0.6833 - val_loss: 0.7769 - val_accuracy: 0.6000\n",
      "Epoch 101/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.7293 - accuracy: 0.6833 - val_loss: 0.7749 - val_accuracy: 0.6000\n",
      "Epoch 102/500\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.7272 - accuracy: 0.6833 - val_loss: 0.7728 - val_accuracy: 0.6000\n",
      "Epoch 103/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.7252 - accuracy: 0.6833 - val_loss: 0.7707 - val_accuracy: 0.6000\n",
      "Epoch 104/500\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.7232 - accuracy: 0.6833 - val_loss: 0.7686 - val_accuracy: 0.6000\n",
      "Epoch 105/500\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.7212 - accuracy: 0.6833 - val_loss: 0.7667 - val_accuracy: 0.6000\n",
      "Epoch 106/500\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.7194 - accuracy: 0.6833 - val_loss: 0.7643 - val_accuracy: 0.6000\n",
      "Epoch 107/500\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7173 - accuracy: 0.6833 - val_loss: 0.7624 - val_accuracy: 0.6000\n",
      "Epoch 108/500\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 0.7153 - accuracy: 0.6833 - val_loss: 0.7604 - val_accuracy: 0.6000\n",
      "Epoch 109/500\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.7135 - accuracy: 0.6833 - val_loss: 0.7582 - val_accuracy: 0.6000\n",
      "Epoch 110/500\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.7115 - accuracy: 0.6833 - val_loss: 0.7562 - val_accuracy: 0.6000\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 221us/sample - loss: 0.7096 - accuracy: 0.6833 - val_loss: 0.7544 - val_accuracy: 0.6000\n",
      "Epoch 112/500\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.7078 - accuracy: 0.6833 - val_loss: 0.7524 - val_accuracy: 0.6000\n",
      "Epoch 113/500\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.7059 - accuracy: 0.6833 - val_loss: 0.7505 - val_accuracy: 0.6000\n",
      "Epoch 114/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.7040 - accuracy: 0.6833 - val_loss: 0.7486 - val_accuracy: 0.6000\n",
      "Epoch 115/500\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.7022 - accuracy: 0.6833 - val_loss: 0.7467 - val_accuracy: 0.6000\n",
      "Epoch 116/500\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.7004 - accuracy: 0.6833 - val_loss: 0.7446 - val_accuracy: 0.6000\n",
      "Epoch 117/500\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.6986 - accuracy: 0.6833 - val_loss: 0.7427 - val_accuracy: 0.6000\n",
      "Epoch 118/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.6968 - accuracy: 0.6833 - val_loss: 0.7408 - val_accuracy: 0.6000\n",
      "Epoch 119/500\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 0.6950 - accuracy: 0.6833 - val_loss: 0.7389 - val_accuracy: 0.6000\n",
      "Epoch 120/500\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 0.6933 - accuracy: 0.6833 - val_loss: 0.7369 - val_accuracy: 0.6000\n",
      "Epoch 121/500\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.6916 - accuracy: 0.6833 - val_loss: 0.7351 - val_accuracy: 0.6000\n",
      "Epoch 122/500\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.6898 - accuracy: 0.6833 - val_loss: 0.7335 - val_accuracy: 0.6000\n",
      "Epoch 123/500\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 0.6881 - accuracy: 0.6833 - val_loss: 0.7319 - val_accuracy: 0.6000\n",
      "Epoch 124/500\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.6865 - accuracy: 0.6833 - val_loss: 0.7301 - val_accuracy: 0.6000\n",
      "Epoch 125/500\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.6848 - accuracy: 0.6833 - val_loss: 0.7283 - val_accuracy: 0.6000\n",
      "Epoch 126/500\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.6831 - accuracy: 0.6833 - val_loss: 0.7267 - val_accuracy: 0.6000\n",
      "Epoch 127/500\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 0.6814 - accuracy: 0.6833 - val_loss: 0.7249 - val_accuracy: 0.6000\n",
      "Epoch 128/500\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.6798 - accuracy: 0.6833 - val_loss: 0.7233 - val_accuracy: 0.6000\n",
      "Epoch 129/500\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.6783 - accuracy: 0.6833 - val_loss: 0.7213 - val_accuracy: 0.6000\n",
      "Epoch 130/500\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6765 - accuracy: 0.6833 - val_loss: 0.7197 - val_accuracy: 0.6000\n",
      "Epoch 131/500\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.6749 - accuracy: 0.6833 - val_loss: 0.7184 - val_accuracy: 0.6000\n",
      "Epoch 132/500\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.6733 - accuracy: 0.6833 - val_loss: 0.7170 - val_accuracy: 0.6000\n",
      "Epoch 133/500\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.6716 - accuracy: 0.6833 - val_loss: 0.7154 - val_accuracy: 0.6000\n",
      "Epoch 134/500\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6701 - accuracy: 0.6833 - val_loss: 0.7137 - val_accuracy: 0.6000\n",
      "Epoch 135/500\n",
      "120/120 [==============================] - 0s 169us/sample - loss: 0.6685 - accuracy: 0.6833 - val_loss: 0.7122 - val_accuracy: 0.6000\n",
      "Epoch 136/500\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.6672 - accuracy: 0.6917 - val_loss: 0.7102 - val_accuracy: 0.6000\n",
      "Epoch 137/500\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.6654 - accuracy: 0.6917 - val_loss: 0.7085 - val_accuracy: 0.6000\n",
      "Epoch 138/500\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.6639 - accuracy: 0.6917 - val_loss: 0.7068 - val_accuracy: 0.6000\n",
      "Epoch 139/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.6623 - accuracy: 0.6917 - val_loss: 0.7053 - val_accuracy: 0.6000\n",
      "Epoch 140/500\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.6609 - accuracy: 0.6917 - val_loss: 0.7040 - val_accuracy: 0.6000\n",
      "Epoch 141/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.6594 - accuracy: 0.6917 - val_loss: 0.7022 - val_accuracy: 0.6000\n",
      "Epoch 142/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.6579 - accuracy: 0.6917 - val_loss: 0.7005 - val_accuracy: 0.6000\n",
      "Epoch 143/500\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 0.6564 - accuracy: 0.6917 - val_loss: 0.6989 - val_accuracy: 0.6000\n",
      "Epoch 144/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.6549 - accuracy: 0.6917 - val_loss: 0.6976 - val_accuracy: 0.6000\n",
      "Epoch 145/500\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.6535 - accuracy: 0.6917 - val_loss: 0.6962 - val_accuracy: 0.6000\n",
      "Epoch 146/500\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.6520 - accuracy: 0.6917 - val_loss: 0.6945 - val_accuracy: 0.6000\n",
      "Epoch 147/500\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.6505 - accuracy: 0.6917 - val_loss: 0.6930 - val_accuracy: 0.6000\n",
      "Epoch 148/500\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.6493 - accuracy: 0.6917 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 149/500\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.6477 - accuracy: 0.6917 - val_loss: 0.6896 - val_accuracy: 0.6000\n",
      "Epoch 150/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.6463 - accuracy: 0.6917 - val_loss: 0.6880 - val_accuracy: 0.6000\n",
      "Epoch 151/500\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.6449 - accuracy: 0.6917 - val_loss: 0.6867 - val_accuracy: 0.6000\n",
      "Epoch 152/500\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.6435 - accuracy: 0.6917 - val_loss: 0.6853 - val_accuracy: 0.6000\n",
      "Epoch 153/500\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6422 - accuracy: 0.6917 - val_loss: 0.6842 - val_accuracy: 0.6000\n",
      "Epoch 154/500\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 0.6408 - accuracy: 0.6917 - val_loss: 0.6827 - val_accuracy: 0.6000\n",
      "Epoch 155/500\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.6394 - accuracy: 0.6917 - val_loss: 0.6812 - val_accuracy: 0.6000\n",
      "Epoch 156/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.6381 - accuracy: 0.7000 - val_loss: 0.6797 - val_accuracy: 0.6333\n",
      "Epoch 157/500\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.6369 - accuracy: 0.7000 - val_loss: 0.6779 - val_accuracy: 0.6333\n",
      "Epoch 158/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.6354 - accuracy: 0.7000 - val_loss: 0.6765 - val_accuracy: 0.6333\n",
      "Epoch 159/500\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 0.6341 - accuracy: 0.7000 - val_loss: 0.6751 - val_accuracy: 0.6333\n",
      "Epoch 160/500\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6328 - accuracy: 0.7000 - val_loss: 0.6737 - val_accuracy: 0.6333\n",
      "Epoch 161/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.6315 - accuracy: 0.7000 - val_loss: 0.6721 - val_accuracy: 0.6333\n",
      "Epoch 162/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.6302 - accuracy: 0.7000 - val_loss: 0.6709 - val_accuracy: 0.6333\n",
      "Epoch 163/500\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.6288 - accuracy: 0.7000 - val_loss: 0.6696 - val_accuracy: 0.6333\n",
      "Epoch 164/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.6276 - accuracy: 0.7000 - val_loss: 0.6682 - val_accuracy: 0.6333\n",
      "Epoch 165/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.6264 - accuracy: 0.7000 - val_loss: 0.6672 - val_accuracy: 0.6333\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 260us/sample - loss: 0.6251 - accuracy: 0.7000 - val_loss: 0.6657 - val_accuracy: 0.6333\n",
      "Epoch 167/500\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.6238 - accuracy: 0.7000 - val_loss: 0.6646 - val_accuracy: 0.6333\n",
      "Epoch 168/500\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.6225 - accuracy: 0.7000 - val_loss: 0.6633 - val_accuracy: 0.6333\n",
      "Epoch 169/500\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.6213 - accuracy: 0.7000 - val_loss: 0.6619 - val_accuracy: 0.6333\n",
      "Epoch 170/500\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.6200 - accuracy: 0.7000 - val_loss: 0.6607 - val_accuracy: 0.6333\n",
      "Epoch 171/500\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.6188 - accuracy: 0.7083 - val_loss: 0.6592 - val_accuracy: 0.6333\n",
      "Epoch 172/500\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.6176 - accuracy: 0.7083 - val_loss: 0.6578 - val_accuracy: 0.6333\n",
      "Epoch 173/500\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.6164 - accuracy: 0.7083 - val_loss: 0.6566 - val_accuracy: 0.6333\n",
      "Epoch 174/500\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.6151 - accuracy: 0.7083 - val_loss: 0.6555 - val_accuracy: 0.6333\n",
      "Epoch 175/500\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.6139 - accuracy: 0.7083 - val_loss: 0.6542 - val_accuracy: 0.6333\n",
      "Epoch 176/500\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.6128 - accuracy: 0.7083 - val_loss: 0.6531 - val_accuracy: 0.6333\n",
      "Epoch 177/500\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.6116 - accuracy: 0.7083 - val_loss: 0.6518 - val_accuracy: 0.6333\n",
      "Epoch 178/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.6104 - accuracy: 0.7083 - val_loss: 0.6505 - val_accuracy: 0.6333\n",
      "Epoch 179/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.6094 - accuracy: 0.7083 - val_loss: 0.6490 - val_accuracy: 0.6333\n",
      "Epoch 180/500\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.6080 - accuracy: 0.7083 - val_loss: 0.6479 - val_accuracy: 0.6333\n",
      "Epoch 181/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.6069 - accuracy: 0.7083 - val_loss: 0.6467 - val_accuracy: 0.6333\n",
      "Epoch 182/500\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.6057 - accuracy: 0.7083 - val_loss: 0.6456 - val_accuracy: 0.6333\n",
      "Epoch 183/500\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 0.6045 - accuracy: 0.7083 - val_loss: 0.6444 - val_accuracy: 0.6333\n",
      "Epoch 184/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.6034 - accuracy: 0.7083 - val_loss: 0.6429 - val_accuracy: 0.6333\n",
      "Epoch 185/500\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.6022 - accuracy: 0.7083 - val_loss: 0.6417 - val_accuracy: 0.6333\n",
      "Epoch 186/500\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.6011 - accuracy: 0.7083 - val_loss: 0.6407 - val_accuracy: 0.6333\n",
      "Epoch 187/500\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.5999 - accuracy: 0.7083 - val_loss: 0.6397 - val_accuracy: 0.6333\n",
      "Epoch 188/500\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.5988 - accuracy: 0.7083 - val_loss: 0.6385 - val_accuracy: 0.6333\n",
      "Epoch 189/500\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5977 - accuracy: 0.7167 - val_loss: 0.6373 - val_accuracy: 0.6333\n",
      "Epoch 190/500\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.5965 - accuracy: 0.7167 - val_loss: 0.6360 - val_accuracy: 0.6333\n",
      "Epoch 191/500\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.5954 - accuracy: 0.7167 - val_loss: 0.6348 - val_accuracy: 0.6333\n",
      "Epoch 192/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5943 - accuracy: 0.7167 - val_loss: 0.6336 - val_accuracy: 0.6333\n",
      "Epoch 193/500\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.62 - 0s 248us/sample - loss: 0.5932 - accuracy: 0.7167 - val_loss: 0.6324 - val_accuracy: 0.6333\n",
      "Epoch 194/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.5921 - accuracy: 0.7167 - val_loss: 0.6313 - val_accuracy: 0.6333\n",
      "Epoch 195/500\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.5911 - accuracy: 0.7167 - val_loss: 0.6304 - val_accuracy: 0.6333\n",
      "Epoch 196/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.5899 - accuracy: 0.7167 - val_loss: 0.6292 - val_accuracy: 0.6333\n",
      "Epoch 197/500\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.5888 - accuracy: 0.7167 - val_loss: 0.6280 - val_accuracy: 0.6333\n",
      "Epoch 198/500\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.5878 - accuracy: 0.7167 - val_loss: 0.6267 - val_accuracy: 0.6333\n",
      "Epoch 199/500\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5866 - accuracy: 0.7250 - val_loss: 0.6254 - val_accuracy: 0.6333\n",
      "Epoch 200/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.5855 - accuracy: 0.7250 - val_loss: 0.6240 - val_accuracy: 0.6333\n",
      "Epoch 201/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5844 - accuracy: 0.7250 - val_loss: 0.6228 - val_accuracy: 0.6333\n",
      "Epoch 202/500\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.5835 - accuracy: 0.7250 - val_loss: 0.6215 - val_accuracy: 0.6333\n",
      "Epoch 203/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5823 - accuracy: 0.7250 - val_loss: 0.6205 - val_accuracy: 0.6333\n",
      "Epoch 204/500\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.5813 - accuracy: 0.7250 - val_loss: 0.6193 - val_accuracy: 0.6333\n",
      "Epoch 205/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.5802 - accuracy: 0.7250 - val_loss: 0.6182 - val_accuracy: 0.6333\n",
      "Epoch 206/500\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.5791 - accuracy: 0.7250 - val_loss: 0.6171 - val_accuracy: 0.6333\n",
      "Epoch 207/500\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.5781 - accuracy: 0.7250 - val_loss: 0.6162 - val_accuracy: 0.6333\n",
      "Epoch 208/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.5770 - accuracy: 0.7250 - val_loss: 0.6153 - val_accuracy: 0.6333\n",
      "Epoch 209/500\n",
      "120/120 [==============================] - 0s 348us/sample - loss: 0.5760 - accuracy: 0.7250 - val_loss: 0.6143 - val_accuracy: 0.6333\n",
      "Epoch 210/500\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.5749 - accuracy: 0.7250 - val_loss: 0.6134 - val_accuracy: 0.6333\n",
      "Epoch 211/500\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.5739 - accuracy: 0.7250 - val_loss: 0.6124 - val_accuracy: 0.6333\n",
      "Epoch 212/500\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 0.5729 - accuracy: 0.7250 - val_loss: 0.6114 - val_accuracy: 0.6333\n",
      "Epoch 213/500\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.5718 - accuracy: 0.7250 - val_loss: 0.6105 - val_accuracy: 0.6333\n",
      "Epoch 214/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5708 - accuracy: 0.7250 - val_loss: 0.6095 - val_accuracy: 0.6667\n",
      "Epoch 215/500\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 0.5698 - accuracy: 0.7250 - val_loss: 0.6083 - val_accuracy: 0.7000\n",
      "Epoch 216/500\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.5688 - accuracy: 0.7250 - val_loss: 0.6069 - val_accuracy: 0.7000\n",
      "Epoch 217/500\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.5677 - accuracy: 0.7250 - val_loss: 0.6058 - val_accuracy: 0.7000\n",
      "Epoch 218/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.5667 - accuracy: 0.7250 - val_loss: 0.6046 - val_accuracy: 0.7000\n",
      "Epoch 219/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.5657 - accuracy: 0.7250 - val_loss: 0.6038 - val_accuracy: 0.7000\n",
      "Epoch 220/500\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.5647 - accuracy: 0.7250 - val_loss: 0.6028 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/500\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.5638 - accuracy: 0.7250 - val_loss: 0.6017 - val_accuracy: 0.7000\n",
      "Epoch 222/500\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.5627 - accuracy: 0.7250 - val_loss: 0.6008 - val_accuracy: 0.7000\n",
      "Epoch 223/500\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5618 - accuracy: 0.7250 - val_loss: 0.5998 - val_accuracy: 0.7000\n",
      "Epoch 224/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5608 - accuracy: 0.7250 - val_loss: 0.5992 - val_accuracy: 0.7000\n",
      "Epoch 225/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5598 - accuracy: 0.7250 - val_loss: 0.5982 - val_accuracy: 0.7000\n",
      "Epoch 226/500\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.5589 - accuracy: 0.7250 - val_loss: 0.5974 - val_accuracy: 0.7000\n",
      "Epoch 227/500\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.5579 - accuracy: 0.7250 - val_loss: 0.5967 - val_accuracy: 0.7000\n",
      "Epoch 228/500\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5569 - accuracy: 0.7250 - val_loss: 0.5958 - val_accuracy: 0.7000\n",
      "Epoch 229/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.5559 - accuracy: 0.7250 - val_loss: 0.5948 - val_accuracy: 0.7000\n",
      "Epoch 230/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.5550 - accuracy: 0.7250 - val_loss: 0.5939 - val_accuracy: 0.7000\n",
      "Epoch 231/500\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5540 - accuracy: 0.7250 - val_loss: 0.5929 - val_accuracy: 0.7000\n",
      "Epoch 232/500\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.5531 - accuracy: 0.7250 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
      "Epoch 233/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5521 - accuracy: 0.7250 - val_loss: 0.5909 - val_accuracy: 0.7000\n",
      "Epoch 234/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5512 - accuracy: 0.7333 - val_loss: 0.5898 - val_accuracy: 0.7000\n",
      "Epoch 235/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5504 - accuracy: 0.7333 - val_loss: 0.5884 - val_accuracy: 0.7000\n",
      "Epoch 236/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.5493 - accuracy: 0.7333 - val_loss: 0.5872 - val_accuracy: 0.7000\n",
      "Epoch 237/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5484 - accuracy: 0.7333 - val_loss: 0.5864 - val_accuracy: 0.7000\n",
      "Epoch 238/500\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.5474 - accuracy: 0.7333 - val_loss: 0.5854 - val_accuracy: 0.7000\n",
      "Epoch 239/500\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.5465 - accuracy: 0.7333 - val_loss: 0.5843 - val_accuracy: 0.7000\n",
      "Epoch 240/500\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.5457 - accuracy: 0.7333 - val_loss: 0.5835 - val_accuracy: 0.7000\n",
      "Epoch 241/500\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.5448 - accuracy: 0.7417 - val_loss: 0.5822 - val_accuracy: 0.7000\n",
      "Epoch 242/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.5438 - accuracy: 0.7500 - val_loss: 0.5812 - val_accuracy: 0.7000\n",
      "Epoch 243/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5429 - accuracy: 0.7500 - val_loss: 0.5802 - val_accuracy: 0.7000\n",
      "Epoch 244/500\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.5419 - accuracy: 0.7500 - val_loss: 0.5792 - val_accuracy: 0.7000\n",
      "Epoch 245/500\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.5410 - accuracy: 0.7500 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 246/500\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.5401 - accuracy: 0.7500 - val_loss: 0.5774 - val_accuracy: 0.7000\n",
      "Epoch 247/500\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.5392 - accuracy: 0.7500 - val_loss: 0.5765 - val_accuracy: 0.7333\n",
      "Epoch 248/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5383 - accuracy: 0.7583 - val_loss: 0.5757 - val_accuracy: 0.7333\n",
      "Epoch 249/500\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.5374 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7000\n",
      "Epoch 250/500\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5366 - accuracy: 0.7583 - val_loss: 0.5738 - val_accuracy: 0.7333\n",
      "Epoch 251/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5356 - accuracy: 0.7583 - val_loss: 0.5730 - val_accuracy: 0.7333\n",
      "Epoch 252/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5347 - accuracy: 0.7583 - val_loss: 0.5724 - val_accuracy: 0.7333\n",
      "Epoch 253/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.5338 - accuracy: 0.7583 - val_loss: 0.5715 - val_accuracy: 0.7333\n",
      "Epoch 254/500\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.5329 - accuracy: 0.7583 - val_loss: 0.5707 - val_accuracy: 0.7333\n",
      "Epoch 255/500\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.5320 - accuracy: 0.7583 - val_loss: 0.5696 - val_accuracy: 0.7333\n",
      "Epoch 256/500\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.5312 - accuracy: 0.7667 - val_loss: 0.5684 - val_accuracy: 0.7333\n",
      "Epoch 257/500\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 0.5304 - accuracy: 0.7750 - val_loss: 0.5672 - val_accuracy: 0.7333\n",
      "Epoch 258/500\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.5294 - accuracy: 0.7750 - val_loss: 0.5665 - val_accuracy: 0.7333\n",
      "Epoch 259/500\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.5285 - accuracy: 0.7750 - val_loss: 0.5657 - val_accuracy: 0.7333\n",
      "Epoch 260/500\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.5276 - accuracy: 0.7750 - val_loss: 0.5650 - val_accuracy: 0.7333\n",
      "Epoch 261/500\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.5270 - accuracy: 0.7750 - val_loss: 0.5643 - val_accuracy: 0.7333\n",
      "Epoch 262/500\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.5259 - accuracy: 0.7750 - val_loss: 0.5634 - val_accuracy: 0.7333\n",
      "Epoch 263/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5251 - accuracy: 0.7750 - val_loss: 0.5621 - val_accuracy: 0.7333\n",
      "Epoch 264/500\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.5241 - accuracy: 0.7833 - val_loss: 0.5610 - val_accuracy: 0.7333\n",
      "Epoch 265/500\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.5236 - accuracy: 0.7833 - val_loss: 0.5594 - val_accuracy: 0.7333\n",
      "Epoch 266/500\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.5225 - accuracy: 0.7833 - val_loss: 0.5584 - val_accuracy: 0.7333\n",
      "Epoch 267/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.5216 - accuracy: 0.7833 - val_loss: 0.5575 - val_accuracy: 0.7333\n",
      "Epoch 268/500\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5207 - accuracy: 0.7833 - val_loss: 0.5567 - val_accuracy: 0.7333\n",
      "Epoch 269/500\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 0.5199 - accuracy: 0.7833 - val_loss: 0.5557 - val_accuracy: 0.7333\n",
      "Epoch 270/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.5190 - accuracy: 0.7833 - val_loss: 0.5549 - val_accuracy: 0.7333\n",
      "Epoch 271/500\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.5182 - accuracy: 0.7833 - val_loss: 0.5539 - val_accuracy: 0.7333\n",
      "Epoch 272/500\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5174 - accuracy: 0.7833 - val_loss: 0.5530 - val_accuracy: 0.7333\n",
      "Epoch 273/500\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5165 - accuracy: 0.7833 - val_loss: 0.5522 - val_accuracy: 0.7333\n",
      "Epoch 274/500\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.5157 - accuracy: 0.7833 - val_loss: 0.5514 - val_accuracy: 0.7333\n",
      "Epoch 275/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5149 - accuracy: 0.7833 - val_loss: 0.5505 - val_accuracy: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/500\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.5140 - accuracy: 0.7833 - val_loss: 0.5492 - val_accuracy: 0.7333\n",
      "Epoch 277/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.5132 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7333\n",
      "Epoch 278/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5123 - accuracy: 0.8000 - val_loss: 0.5472 - val_accuracy: 0.7333\n",
      "Epoch 279/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5115 - accuracy: 0.8000 - val_loss: 0.5461 - val_accuracy: 0.7667\n",
      "Epoch 280/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.5107 - accuracy: 0.8000 - val_loss: 0.5452 - val_accuracy: 0.7667\n",
      "Epoch 281/500\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5099 - accuracy: 0.8000 - val_loss: 0.5447 - val_accuracy: 0.7667\n",
      "Epoch 282/500\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.5089 - accuracy: 0.8000 - val_loss: 0.5440 - val_accuracy: 0.7667\n",
      "Epoch 283/500\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.5082 - accuracy: 0.8000 - val_loss: 0.5434 - val_accuracy: 0.7333\n",
      "Epoch 284/500\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.5073 - accuracy: 0.8000 - val_loss: 0.5425 - val_accuracy: 0.7667\n",
      "Epoch 285/500\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.5065 - accuracy: 0.8000 - val_loss: 0.5419 - val_accuracy: 0.7333\n",
      "Epoch 286/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.5057 - accuracy: 0.8000 - val_loss: 0.5409 - val_accuracy: 0.7667\n",
      "Epoch 287/500\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.5050 - accuracy: 0.8000 - val_loss: 0.5403 - val_accuracy: 0.7667\n",
      "Epoch 288/500\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.5040 - accuracy: 0.8000 - val_loss: 0.5394 - val_accuracy: 0.7667\n",
      "Epoch 289/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.5033 - accuracy: 0.8083 - val_loss: 0.5383 - val_accuracy: 0.7667\n",
      "Epoch 290/500\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.5024 - accuracy: 0.8083 - val_loss: 0.5374 - val_accuracy: 0.7667\n",
      "Epoch 291/500\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.5015 - accuracy: 0.8083 - val_loss: 0.5364 - val_accuracy: 0.7667\n",
      "Epoch 292/500\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.5008 - accuracy: 0.8167 - val_loss: 0.5353 - val_accuracy: 0.7667\n",
      "Epoch 293/500\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.4999 - accuracy: 0.8167 - val_loss: 0.5345 - val_accuracy: 0.7667\n",
      "Epoch 294/500\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.4991 - accuracy: 0.8167 - val_loss: 0.5335 - val_accuracy: 0.8000\n",
      "Epoch 295/500\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.4983 - accuracy: 0.8167 - val_loss: 0.5327 - val_accuracy: 0.8000\n",
      "Epoch 296/500\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.81 - 0s 258us/sample - loss: 0.4975 - accuracy: 0.8167 - val_loss: 0.5319 - val_accuracy: 0.8000\n",
      "Epoch 297/500\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.4968 - accuracy: 0.8167 - val_loss: 0.5309 - val_accuracy: 0.8333\n",
      "Epoch 298/500\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 0.4958 - accuracy: 0.8167 - val_loss: 0.5303 - val_accuracy: 0.8000\n",
      "Epoch 299/500\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.4952 - accuracy: 0.8167 - val_loss: 0.5296 - val_accuracy: 0.8000\n",
      "Epoch 300/500\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.4943 - accuracy: 0.8167 - val_loss: 0.5288 - val_accuracy: 0.8000\n",
      "Epoch 301/500\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4936 - accuracy: 0.8167 - val_loss: 0.5282 - val_accuracy: 0.8000\n",
      "Epoch 302/500\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.4928 - accuracy: 0.8167 - val_loss: 0.5275 - val_accuracy: 0.8000\n",
      "Epoch 303/500\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.4920 - accuracy: 0.8167 - val_loss: 0.5262 - val_accuracy: 0.8333\n",
      "Epoch 304/500\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.4911 - accuracy: 0.8167 - val_loss: 0.5252 - val_accuracy: 0.8333\n",
      "Epoch 305/500\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.4903 - accuracy: 0.8167 - val_loss: 0.5244 - val_accuracy: 0.8333\n",
      "Epoch 306/500\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.4896 - accuracy: 0.8167 - val_loss: 0.5234 - val_accuracy: 0.8333\n",
      "Epoch 307/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.4886 - accuracy: 0.8167 - val_loss: 0.5227 - val_accuracy: 0.8333\n",
      "Epoch 308/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.4879 - accuracy: 0.8167 - val_loss: 0.5221 - val_accuracy: 0.8333\n",
      "Epoch 309/500\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.4872 - accuracy: 0.8167 - val_loss: 0.5217 - val_accuracy: 0.8333\n",
      "Epoch 310/500\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.4864 - accuracy: 0.8167 - val_loss: 0.5210 - val_accuracy: 0.8333\n",
      "Epoch 311/500\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.4856 - accuracy: 0.8167 - val_loss: 0.5203 - val_accuracy: 0.8333\n",
      "Epoch 312/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.4848 - accuracy: 0.8167 - val_loss: 0.5194 - val_accuracy: 0.8333\n",
      "Epoch 313/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.4841 - accuracy: 0.8167 - val_loss: 0.5182 - val_accuracy: 0.8333\n",
      "Epoch 314/500\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 0.4832 - accuracy: 0.8167 - val_loss: 0.5172 - val_accuracy: 0.8333\n",
      "Epoch 315/500\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.4824 - accuracy: 0.8167 - val_loss: 0.5162 - val_accuracy: 0.8333\n",
      "Epoch 316/500\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.4816 - accuracy: 0.8167 - val_loss: 0.5154 - val_accuracy: 0.8333\n",
      "Epoch 317/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.4809 - accuracy: 0.8167 - val_loss: 0.5146 - val_accuracy: 0.8333\n",
      "Epoch 318/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.4800 - accuracy: 0.8167 - val_loss: 0.5133 - val_accuracy: 0.8333\n",
      "Epoch 319/500\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.4793 - accuracy: 0.8167 - val_loss: 0.5123 - val_accuracy: 0.8333\n",
      "Epoch 320/500\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.4784 - accuracy: 0.8167 - val_loss: 0.5115 - val_accuracy: 0.8333\n",
      "Epoch 321/500\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4777 - accuracy: 0.8167 - val_loss: 0.5106 - val_accuracy: 0.8333\n",
      "Epoch 322/500\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.4769 - accuracy: 0.8167 - val_loss: 0.5099 - val_accuracy: 0.8333\n",
      "Epoch 323/500\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.4761 - accuracy: 0.8167 - val_loss: 0.5091 - val_accuracy: 0.8333\n",
      "Epoch 324/500\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.4753 - accuracy: 0.8167 - val_loss: 0.5081 - val_accuracy: 0.8333\n",
      "Epoch 325/500\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4746 - accuracy: 0.8167 - val_loss: 0.5073 - val_accuracy: 0.8333\n",
      "Epoch 326/500\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.4738 - accuracy: 0.8167 - val_loss: 0.5063 - val_accuracy: 0.8333\n",
      "Epoch 327/500\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.4731 - accuracy: 0.8167 - val_loss: 0.5054 - val_accuracy: 0.8333\n",
      "Epoch 328/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.4723 - accuracy: 0.8167 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
      "Epoch 329/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4715 - accuracy: 0.8167 - val_loss: 0.5039 - val_accuracy: 0.8333\n",
      "Epoch 330/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.4708 - accuracy: 0.8167 - val_loss: 0.5034 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/500\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.4699 - accuracy: 0.8167 - val_loss: 0.5026 - val_accuracy: 0.8333\n",
      "Epoch 332/500\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.4691 - accuracy: 0.8167 - val_loss: 0.5017 - val_accuracy: 0.8333\n",
      "Epoch 333/500\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.4683 - accuracy: 0.8167 - val_loss: 0.5009 - val_accuracy: 0.8333\n",
      "Epoch 334/500\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.4676 - accuracy: 0.8250 - val_loss: 0.5000 - val_accuracy: 0.8333\n",
      "Epoch 335/500\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.4668 - accuracy: 0.8167 - val_loss: 0.4993 - val_accuracy: 0.8333\n",
      "Epoch 336/500\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.4660 - accuracy: 0.8167 - val_loss: 0.4986 - val_accuracy: 0.8333\n",
      "Epoch 337/500\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.4653 - accuracy: 0.8167 - val_loss: 0.4980 - val_accuracy: 0.8333\n",
      "Epoch 338/500\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 0.4644 - accuracy: 0.8167 - val_loss: 0.4972 - val_accuracy: 0.8333\n",
      "Epoch 339/500\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.4638 - accuracy: 0.8167 - val_loss: 0.4961 - val_accuracy: 0.8667\n",
      "Epoch 340/500\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.4629 - accuracy: 0.8250 - val_loss: 0.4953 - val_accuracy: 0.8667\n",
      "Epoch 341/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.4621 - accuracy: 0.8250 - val_loss: 0.4944 - val_accuracy: 0.8667\n",
      "Epoch 342/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4613 - accuracy: 0.8250 - val_loss: 0.4936 - val_accuracy: 0.8667\n",
      "Epoch 343/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4606 - accuracy: 0.8250 - val_loss: 0.4929 - val_accuracy: 0.8667\n",
      "Epoch 344/500\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.4598 - accuracy: 0.8250 - val_loss: 0.4919 - val_accuracy: 0.8667\n",
      "Epoch 345/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4590 - accuracy: 0.8333 - val_loss: 0.4910 - val_accuracy: 0.8667\n",
      "Epoch 346/500\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.4582 - accuracy: 0.8417 - val_loss: 0.4901 - val_accuracy: 0.8667\n",
      "Epoch 347/500\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4575 - accuracy: 0.8417 - val_loss: 0.4891 - val_accuracy: 0.9000\n",
      "Epoch 348/500\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 0.4567 - accuracy: 0.8417 - val_loss: 0.4884 - val_accuracy: 0.9000\n",
      "Epoch 349/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4559 - accuracy: 0.8417 - val_loss: 0.4876 - val_accuracy: 0.9000\n",
      "Epoch 350/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.4551 - accuracy: 0.8417 - val_loss: 0.4868 - val_accuracy: 0.9000\n",
      "Epoch 351/500\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.4544 - accuracy: 0.8417 - val_loss: 0.4860 - val_accuracy: 0.9000\n",
      "Epoch 352/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.4536 - accuracy: 0.8417 - val_loss: 0.4850 - val_accuracy: 0.9000\n",
      "Epoch 353/500\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.4528 - accuracy: 0.8417 - val_loss: 0.4841 - val_accuracy: 0.9000\n",
      "Epoch 354/500\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.4524 - accuracy: 0.8417 - val_loss: 0.4837 - val_accuracy: 0.9000\n",
      "Epoch 355/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.4512 - accuracy: 0.8417 - val_loss: 0.4827 - val_accuracy: 0.9000\n",
      "Epoch 356/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.4505 - accuracy: 0.8417 - val_loss: 0.4816 - val_accuracy: 0.9000\n",
      "Epoch 357/500\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.4497 - accuracy: 0.8417 - val_loss: 0.4807 - val_accuracy: 0.9000\n",
      "Epoch 358/500\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.4489 - accuracy: 0.8417 - val_loss: 0.4798 - val_accuracy: 0.9000\n",
      "Epoch 359/500\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.4481 - accuracy: 0.8417 - val_loss: 0.4789 - val_accuracy: 0.9000\n",
      "Epoch 360/500\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.4474 - accuracy: 0.8417 - val_loss: 0.4780 - val_accuracy: 0.9000\n",
      "Epoch 361/500\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.4466 - accuracy: 0.8333 - val_loss: 0.4772 - val_accuracy: 0.9000\n",
      "Epoch 362/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.4458 - accuracy: 0.8417 - val_loss: 0.4766 - val_accuracy: 0.9000\n",
      "Epoch 363/500\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.4451 - accuracy: 0.8417 - val_loss: 0.4759 - val_accuracy: 0.9000\n",
      "Epoch 364/500\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.4443 - accuracy: 0.8417 - val_loss: 0.4752 - val_accuracy: 0.9000\n",
      "Epoch 365/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4435 - accuracy: 0.8417 - val_loss: 0.4742 - val_accuracy: 0.9000\n",
      "Epoch 366/500\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.4427 - accuracy: 0.8417 - val_loss: 0.4733 - val_accuracy: 0.9000\n",
      "Epoch 367/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4420 - accuracy: 0.8333 - val_loss: 0.4726 - val_accuracy: 0.9000\n",
      "Epoch 368/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4412 - accuracy: 0.8417 - val_loss: 0.4717 - val_accuracy: 0.9000\n",
      "Epoch 369/500\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4404 - accuracy: 0.8333 - val_loss: 0.4707 - val_accuracy: 0.9000\n",
      "Epoch 370/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.4397 - accuracy: 0.8333 - val_loss: 0.4697 - val_accuracy: 0.9000\n",
      "Epoch 371/500\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.4388 - accuracy: 0.8417 - val_loss: 0.4688 - val_accuracy: 0.9000\n",
      "Epoch 372/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4381 - accuracy: 0.8417 - val_loss: 0.4679 - val_accuracy: 0.9000\n",
      "Epoch 373/500\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.4373 - accuracy: 0.8417 - val_loss: 0.4672 - val_accuracy: 0.9000\n",
      "Epoch 374/500\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.4366 - accuracy: 0.8417 - val_loss: 0.4662 - val_accuracy: 0.9000\n",
      "Epoch 375/500\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.4357 - accuracy: 0.8500 - val_loss: 0.4653 - val_accuracy: 0.9000\n",
      "Epoch 376/500\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.4350 - accuracy: 0.8500 - val_loss: 0.4646 - val_accuracy: 0.9000\n",
      "Epoch 377/500\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4793 - accuracy: 0.78 - 0s 264us/sample - loss: 0.4341 - accuracy: 0.8500 - val_loss: 0.4636 - val_accuracy: 0.9000\n",
      "Epoch 378/500\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.4336 - accuracy: 0.8583 - val_loss: 0.4624 - val_accuracy: 0.9333\n",
      "Epoch 379/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.4329 - accuracy: 0.8583 - val_loss: 0.4619 - val_accuracy: 0.9000\n",
      "Epoch 380/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.4318 - accuracy: 0.8583 - val_loss: 0.4610 - val_accuracy: 0.9000\n",
      "Epoch 381/500\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.4311 - accuracy: 0.8583 - val_loss: 0.4602 - val_accuracy: 0.9000\n",
      "Epoch 382/500\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.4302 - accuracy: 0.8583 - val_loss: 0.4592 - val_accuracy: 0.9333\n",
      "Epoch 383/500\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.4295 - accuracy: 0.8583 - val_loss: 0.4581 - val_accuracy: 0.9333\n",
      "Epoch 384/500\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.4288 - accuracy: 0.8667 - val_loss: 0.4570 - val_accuracy: 0.9333\n",
      "Epoch 385/500\n",
      "120/120 [==============================] - 0s 368us/sample - loss: 0.4280 - accuracy: 0.8667 - val_loss: 0.4562 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.4272 - accuracy: 0.8667 - val_loss: 0.4556 - val_accuracy: 0.9333\n",
      "Epoch 387/500\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.4264 - accuracy: 0.8667 - val_loss: 0.4547 - val_accuracy: 0.9333\n",
      "Epoch 388/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4257 - accuracy: 0.8667 - val_loss: 0.4538 - val_accuracy: 0.9333\n",
      "Epoch 389/500\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.4248 - accuracy: 0.8667 - val_loss: 0.4532 - val_accuracy: 0.9333\n",
      "Epoch 390/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.4241 - accuracy: 0.8667 - val_loss: 0.4524 - val_accuracy: 0.9333\n",
      "Epoch 391/500\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.4232 - accuracy: 0.8667 - val_loss: 0.4518 - val_accuracy: 0.9333\n",
      "Epoch 392/500\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.4226 - accuracy: 0.8583 - val_loss: 0.4513 - val_accuracy: 0.9333\n",
      "Epoch 393/500\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.4217 - accuracy: 0.8583 - val_loss: 0.4506 - val_accuracy: 0.9333\n",
      "Epoch 394/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.4210 - accuracy: 0.8583 - val_loss: 0.4497 - val_accuracy: 0.9333\n",
      "Epoch 395/500\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.4202 - accuracy: 0.8583 - val_loss: 0.4488 - val_accuracy: 0.9333\n",
      "Epoch 396/500\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.4194 - accuracy: 0.8667 - val_loss: 0.4477 - val_accuracy: 0.9333\n",
      "Epoch 397/500\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.4186 - accuracy: 0.8667 - val_loss: 0.4469 - val_accuracy: 0.9333\n",
      "Epoch 398/500\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.4179 - accuracy: 0.8667 - val_loss: 0.4460 - val_accuracy: 0.9333\n",
      "Epoch 399/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4171 - accuracy: 0.8667 - val_loss: 0.4454 - val_accuracy: 0.9333\n",
      "Epoch 400/500\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.4164 - accuracy: 0.8667 - val_loss: 0.4444 - val_accuracy: 0.9667\n",
      "Epoch 401/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.4156 - accuracy: 0.8667 - val_loss: 0.4435 - val_accuracy: 0.9667\n",
      "Epoch 402/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.4148 - accuracy: 0.8667 - val_loss: 0.4429 - val_accuracy: 0.9667\n",
      "Epoch 403/500\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4140 - accuracy: 0.8667 - val_loss: 0.4421 - val_accuracy: 0.9667\n",
      "Epoch 404/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4132 - accuracy: 0.8667 - val_loss: 0.4415 - val_accuracy: 0.9333\n",
      "Epoch 405/500\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.4125 - accuracy: 0.8667 - val_loss: 0.4407 - val_accuracy: 0.9333\n",
      "Epoch 406/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.4117 - accuracy: 0.8667 - val_loss: 0.4397 - val_accuracy: 0.9667\n",
      "Epoch 407/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.4109 - accuracy: 0.8667 - val_loss: 0.4391 - val_accuracy: 0.9667\n",
      "Epoch 408/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4102 - accuracy: 0.8667 - val_loss: 0.4380 - val_accuracy: 0.9667\n",
      "Epoch 409/500\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.4094 - accuracy: 0.8917 - val_loss: 0.4371 - val_accuracy: 0.9667\n",
      "Epoch 410/500\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.4086 - accuracy: 0.8750 - val_loss: 0.4365 - val_accuracy: 0.9667\n",
      "Epoch 411/500\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.4079 - accuracy: 0.8750 - val_loss: 0.4358 - val_accuracy: 0.9667\n",
      "Epoch 412/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.4071 - accuracy: 0.8750 - val_loss: 0.4349 - val_accuracy: 0.9667\n",
      "Epoch 413/500\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.4064 - accuracy: 0.8750 - val_loss: 0.4342 - val_accuracy: 0.9667\n",
      "Epoch 414/500\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.4055 - accuracy: 0.8833 - val_loss: 0.4332 - val_accuracy: 0.9667\n",
      "Epoch 415/500\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.4047 - accuracy: 0.8917 - val_loss: 0.4320 - val_accuracy: 0.9667\n",
      "Epoch 416/500\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.4040 - accuracy: 0.8917 - val_loss: 0.4309 - val_accuracy: 0.9667\n",
      "Epoch 417/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4032 - accuracy: 0.8917 - val_loss: 0.4302 - val_accuracy: 0.9667\n",
      "Epoch 418/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.4024 - accuracy: 0.8917 - val_loss: 0.4292 - val_accuracy: 0.9667\n",
      "Epoch 419/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.4016 - accuracy: 0.8917 - val_loss: 0.4282 - val_accuracy: 0.9667\n",
      "Epoch 420/500\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.4009 - accuracy: 0.8917 - val_loss: 0.4272 - val_accuracy: 0.9667\n",
      "Epoch 421/500\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.4001 - accuracy: 0.9000 - val_loss: 0.4264 - val_accuracy: 0.9667\n",
      "Epoch 422/500\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.3993 - accuracy: 0.9000 - val_loss: 0.4256 - val_accuracy: 0.9667\n",
      "Epoch 423/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.3985 - accuracy: 0.9000 - val_loss: 0.4249 - val_accuracy: 0.9667\n",
      "Epoch 424/500\n",
      "120/120 [==============================] - 0s 348us/sample - loss: 0.3978 - accuracy: 0.9000 - val_loss: 0.4240 - val_accuracy: 0.9667\n",
      "Epoch 425/500\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.3970 - accuracy: 0.9000 - val_loss: 0.4232 - val_accuracy: 0.9667\n",
      "Epoch 426/500\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.3963 - accuracy: 0.9000 - val_loss: 0.4225 - val_accuracy: 0.9667\n",
      "Epoch 427/500\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.3954 - accuracy: 0.9000 - val_loss: 0.4218 - val_accuracy: 0.9667\n",
      "Epoch 428/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3948 - accuracy: 0.8917 - val_loss: 0.4212 - val_accuracy: 0.9667\n",
      "Epoch 429/500\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.3940 - accuracy: 0.8917 - val_loss: 0.4204 - val_accuracy: 0.9667\n",
      "Epoch 430/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3933 - accuracy: 0.9000 - val_loss: 0.4192 - val_accuracy: 0.9667\n",
      "Epoch 431/500\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.3924 - accuracy: 0.9083 - val_loss: 0.4183 - val_accuracy: 0.9667\n",
      "Epoch 432/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3917 - accuracy: 0.9083 - val_loss: 0.4173 - val_accuracy: 0.9667\n",
      "Epoch 433/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3909 - accuracy: 0.9083 - val_loss: 0.4165 - val_accuracy: 0.9667\n",
      "Epoch 434/500\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.3901 - accuracy: 0.9083 - val_loss: 0.4157 - val_accuracy: 0.9667\n",
      "Epoch 435/500\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.3893 - accuracy: 0.9083 - val_loss: 0.4149 - val_accuracy: 0.9667\n",
      "Epoch 436/500\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.3887 - accuracy: 0.9083 - val_loss: 0.4139 - val_accuracy: 0.9667\n",
      "Epoch 437/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.3878 - accuracy: 0.9083 - val_loss: 0.4131 - val_accuracy: 0.9667\n",
      "Epoch 438/500\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.3871 - accuracy: 0.9083 - val_loss: 0.4124 - val_accuracy: 0.9667\n",
      "Epoch 439/500\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.3863 - accuracy: 0.9167 - val_loss: 0.4114 - val_accuracy: 0.9667\n",
      "Epoch 440/500\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.3855 - accuracy: 0.9167 - val_loss: 0.4105 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/500\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 0.3847 - accuracy: 0.9167 - val_loss: 0.4097 - val_accuracy: 0.9667\n",
      "Epoch 442/500\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.3839 - accuracy: 0.9167 - val_loss: 0.4088 - val_accuracy: 0.9667\n",
      "Epoch 443/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3832 - accuracy: 0.9167 - val_loss: 0.4080 - val_accuracy: 0.9667\n",
      "Epoch 444/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.3825 - accuracy: 0.9167 - val_loss: 0.4073 - val_accuracy: 0.9667\n",
      "Epoch 445/500\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.3816 - accuracy: 0.9167 - val_loss: 0.4065 - val_accuracy: 0.9667\n",
      "Epoch 446/500\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.3809 - accuracy: 0.9167 - val_loss: 0.4057 - val_accuracy: 0.9667\n",
      "Epoch 447/500\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.3802 - accuracy: 0.9167 - val_loss: 0.4047 - val_accuracy: 0.9667\n",
      "Epoch 448/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.3794 - accuracy: 0.9167 - val_loss: 0.4040 - val_accuracy: 0.9667\n",
      "Epoch 449/500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.3785 - accuracy: 0.9167 - val_loss: 0.4031 - val_accuracy: 0.9667\n",
      "Epoch 450/500\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.3778 - accuracy: 0.9167 - val_loss: 0.4021 - val_accuracy: 0.9667\n",
      "Epoch 451/500\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.3770 - accuracy: 0.9250 - val_loss: 0.4013 - val_accuracy: 0.9667\n",
      "Epoch 452/500\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 0.3762 - accuracy: 0.9250 - val_loss: 0.4005 - val_accuracy: 0.9667\n",
      "Epoch 453/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.3754 - accuracy: 0.9250 - val_loss: 0.3996 - val_accuracy: 0.9667\n",
      "Epoch 454/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.3747 - accuracy: 0.9250 - val_loss: 0.3988 - val_accuracy: 0.9667\n",
      "Epoch 455/500\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.3741 - accuracy: 0.9250 - val_loss: 0.3978 - val_accuracy: 0.9667\n",
      "Epoch 456/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.3731 - accuracy: 0.9250 - val_loss: 0.3970 - val_accuracy: 0.9667\n",
      "Epoch 457/500\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.3726 - accuracy: 0.9250 - val_loss: 0.3964 - val_accuracy: 0.9667\n",
      "Epoch 458/500\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3717 - accuracy: 0.9250 - val_loss: 0.3954 - val_accuracy: 0.9667\n",
      "Epoch 459/500\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.3713 - accuracy: 0.9250 - val_loss: 0.3949 - val_accuracy: 0.9667\n",
      "Epoch 460/500\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.3701 - accuracy: 0.9250 - val_loss: 0.3939 - val_accuracy: 0.9667\n",
      "Epoch 461/500\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.3693 - accuracy: 0.9250 - val_loss: 0.3929 - val_accuracy: 0.9667\n",
      "Epoch 462/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.3685 - accuracy: 0.9250 - val_loss: 0.3921 - val_accuracy: 0.9667\n",
      "Epoch 463/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.3678 - accuracy: 0.9250 - val_loss: 0.3913 - val_accuracy: 0.9667\n",
      "Epoch 464/500\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.3670 - accuracy: 0.9250 - val_loss: 0.3904 - val_accuracy: 0.9667\n",
      "Epoch 465/500\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.3662 - accuracy: 0.9250 - val_loss: 0.3895 - val_accuracy: 0.9667\n",
      "Epoch 466/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3655 - accuracy: 0.9250 - val_loss: 0.3888 - val_accuracy: 0.9667\n",
      "Epoch 467/500\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.3648 - accuracy: 0.9250 - val_loss: 0.3878 - val_accuracy: 0.9667\n",
      "Epoch 468/500\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.3640 - accuracy: 0.9250 - val_loss: 0.3871 - val_accuracy: 0.9667\n",
      "Epoch 469/500\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.3632 - accuracy: 0.9250 - val_loss: 0.3862 - val_accuracy: 0.9667\n",
      "Epoch 470/500\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.3624 - accuracy: 0.9250 - val_loss: 0.3855 - val_accuracy: 0.9667\n",
      "Epoch 471/500\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3616 - accuracy: 0.9250 - val_loss: 0.3847 - val_accuracy: 0.9667\n",
      "Epoch 472/500\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.3609 - accuracy: 0.9250 - val_loss: 0.3840 - val_accuracy: 0.9667\n",
      "Epoch 473/500\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.3601 - accuracy: 0.9250 - val_loss: 0.3833 - val_accuracy: 0.9667\n",
      "Epoch 474/500\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.3593 - accuracy: 0.9250 - val_loss: 0.3824 - val_accuracy: 0.9667\n",
      "Epoch 475/500\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.3586 - accuracy: 0.9250 - val_loss: 0.3815 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.3578 - accuracy: 0.9250 - val_loss: 0.3806 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.3571 - accuracy: 0.9250 - val_loss: 0.3797 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.3563 - accuracy: 0.9250 - val_loss: 0.3789 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.3556 - accuracy: 0.9250 - val_loss: 0.3780 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.3548 - accuracy: 0.9250 - val_loss: 0.3773 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.3540 - accuracy: 0.9250 - val_loss: 0.3764 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3533 - accuracy: 0.9250 - val_loss: 0.3756 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.3525 - accuracy: 0.9250 - val_loss: 0.3746 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.3521 - accuracy: 0.9250 - val_loss: 0.3740 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.3510 - accuracy: 0.9250 - val_loss: 0.3730 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.3507 - accuracy: 0.9333 - val_loss: 0.3719 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.3495 - accuracy: 0.9417 - val_loss: 0.3711 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.3487 - accuracy: 0.9417 - val_loss: 0.3703 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.3480 - accuracy: 0.9417 - val_loss: 0.3697 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.3473 - accuracy: 0.9333 - val_loss: 0.3688 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.3465 - accuracy: 0.9333 - val_loss: 0.3680 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3459 - accuracy: 0.9250 - val_loss: 0.3674 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.3450 - accuracy: 0.9250 - val_loss: 0.3666 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.3443 - accuracy: 0.9250 - val_loss: 0.3658 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.3435 - accuracy: 0.9333 - val_loss: 0.3649 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.3427 - accuracy: 0.9417 - val_loss: 0.3640 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.3421 - accuracy: 0.9417 - val_loss: 0.3630 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.3412 - accuracy: 0.9417 - val_loss: 0.3621 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.3405 - accuracy: 0.9417 - val_loss: 0.3613 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.3398 - accuracy: 0.9417 - val_loss: 0.3604 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cf521f8788>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train,y_train,epochs=500,validation_data=(scaled_X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cf504c2b48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deVyVZf7/8dfFJqIoyqosKm6A4pK4VZprWrmWmZpZtjgtWk3LVN+aaZt+LTPtNTVNmVNjLpmZZWmumWuCoggoigmyCIiKuCDLuX5/XEcjA2Q5nMPyeT4ePOTc5zr3fZ27R28vr/talNYaIYQQ9Z+ToysghBDCNiTQhRCigZBAF0KIBkICXQghGggJdCGEaCBcHHVhHx8f3b59e0ddXggh6qWYmJhjWmvfst5zWKC3b9+e6OhoR11eCCHqJaVUSnnvSZeLEEI0EJcNdKXUXKVUtlJqbznvhymltiqlziulHrN9FYUQQlRGZVro84DRFbx/HHgQ+KctKiSEEKJ6LtuHrrXeqJRqX8H72UC2UuoGG9ZLCNFAFRUVkZaWRkFBgaOrUqe5u7sTFBSEq6trpT9j14eiSqlZwCyAkJAQe15aCFFHpKWl4enpSfv27VFKObo6dZLWmtzcXNLS0ujQoUOlP2fXh6Ja64+01lFa6yhf3zJH3QghGriCggK8vb0lzCuglMLb27vK/4qRUS5CCLuTML+86twjxwX66SyQpXuFEMJmKjNscQGwFeiqlEpTSt2llLpXKXWv9f0ApVQa8AjwjLVMi8te+VQGrHlWQl0IYXfNmzd3dBVqRWVGuUy9zPtHgaCqXviEagmb3wb3ljDo0ap+XAghxCUc1uWSob1Z73YNrH0BEr9zVDWEEI2Y1prHH3+c7t27ExkZyaJFiwDIzMxk8ODB9OrVi+7du/Pzzz9TUlLCHXfccbHsm2++6eDa/5HD1nIJad2M+/Nn8p1nFqFL70HdvRb8IxxVHSGEAzz/bTwJGadses6Iti14dmy3SpVdunQpsbGx7N69m2PHjtG3b18GDx7MF198wahRo3j66acpKSnh7NmzxMbGkp6ezt69ZtL8yZMnbVpvW3BYC93T3YUnx/ZmyqkHOUdT+OpuKJKJBkII+9m0aRNTp07F2dkZf39/rrnmGnbs2EHfvn359NNPee6554iLi8PT05PQ0FAOHTrEnDlzWLlyJS1aXP5Rob05rIUOMGNgO3YcPs7s+LuZW/QqrH0eRr/syCoJIeyosi3p2qLLGZQxePBgNm7cyIoVK7jtttt4/PHHmTFjBrt372bVqlW8//77LF68mLlz59q5xhVz6Dh0pRQv3xhJstdAFjtfD9v+BYc2OLJKQohGZPDgwSxatIiSkhJycnLYuHEj/fr1IyUlBT8/P+655x7uuusudu7cybFjx7BYLNx00028+OKL7Ny509HV/wOHttABPN1deWdKb6b8azLDPPfg890jcN8WcHV3dNWEEA3cxIkT2bp1Kz179kQpxWuvvUZAQAD//e9/+cc//oGrqyvNmzfns88+Iz09nZkzZ2KxWAB4+eW615ugyvsnR22LiorSpTe4eOWHfcT//DWfu70CQ/4PhjzhkHoJIWpXYmIi4eHhjq5GvVDWvVJKxWito8oqX2em/j88ojMZ3gNZ43Q1+ufXITfZ0VUSQoh6pc4EururMy9NjOT/zk6lCBf4/jGZRSqEEFVQZwIdYECoN93DuvJ6yWRIXgfxSx1dJSGEqDfqVKAD/GV0Vz4+P5xMj66w6mk4f9rRVRJCiHqhzgV6WEALJl4RwkOnboX8TPhZdrYTQojKqHOBDvDnkV2IpQvRLUfBlvfkAakQQlRCnQz0QK+mTO/fjgdyJmBxbgIrn3R0lYQQos6rk4EO8KdrQjnh1IrvvW+HAz/C/pWOrpIQohGqaO30w4cP0717dzvWpmJ1NtD9W7gzrV8Ij6cOoKhVJ9NKLzrn6GoJIUSd5fCp/xX50zWhfLE9lf96zebuXx+Gjf+E4X91dLWEELbyw5NwNM625wyIhOteKfftJ554gnbt2nH//fcD8Nxzz6GUYuPGjZw4cYKioiL+/ve/M378+CpdtqCggPvuu4/o6GhcXFx44403GDp0KPHx8cycOZPCwkIsFgtfffUVbdu2ZfLkyaSlpVFSUsJf//pXbrnllhp9bajDLXSANi2bcnNUEK8lBXAuYjJsfguyEhxdLSFEPTZlypSLG1kALF68mJkzZ/L111+zc+dO1q9fz6OPPlruSozlef/99wGIi4tjwYIF3H777RQUFPDhhx/y0EMPERsbS3R0NEFBQaxcuZK2bduye/du9u7dy+jRo23y3S7bQldKzQXGANla6z90FimzNfXbwPXAWeAOrbXNliGbNTiUBb+k8m/3O3m4yRr49kG480dwqtN/FwkhKqOClnRt6d27N9nZ2WRkZJCTk0OrVq1o06YNf/7zn9m4cSNOTk6kp6eTlZVFQEBApc+7adMm5syZA0BYWBjt2rUjKSmJgQMH8tJLL5GWlsaNN95I586diYyM5LHHHuOJJ55gzJgxDBo0yCbfrTKpOA+o6K+P64DO1p9ZwAc1r9Zv2nk34/rINnwcc4qzw/4OaTsg+hNbXkII0chMmjSJJUuWsGjRIqZMmcL8+fPJyckhJiaG2NhY/P39KSio2oY75bXop02bxvLly2natCmjRo1i3bp1dOnShZiYGCIjI3nqqad44YUXbPG1Lh/oWuuNwPEKiowHPtPGNsBLKdXGJrWzum9IR06fL2buqb4QOgTWPA+nMmx5CSFEIzJlyhQWLlzIkiVLmDRpEnl5efj5+eHq6sr69etJSUmp8jkHDx7M/PnzAUhKSiI1NZWuXbty6NAhQkNDefDBBxk3bhx79uwhIyMDDw8Ppk+fzmOPPWaztdVt0W8RCBwp9TrNeuwPlFKzlFLRSqnonJycSl+gW9uWDOnqy9wtKRSMeh0sRfD94zWrtRCi0erWrRv5+fkEBgbSpk0bbr31VqKjo4mKimL+/PmEhYVV+Zz3338/JSUlREZGcssttzBv3jyaNGnCokWL6N69O7169WLfvn3MmDGDuLg4+vXrR69evXjppZd45plnbPK9KrUeulKqPfBdOX3oK4CXtdabrK/XAn/RWsdUdM5L10O/nB2Hj3Pzh1t5dmwEM/UyWPMc3DIfwsdU+hxCCMeT9dArzxHroacBwaVeBwE27w/p2741/dq35qONhyjsez/4dzet9ALb7hguhBD1lS0CfTkwQxkDgDytdaYNzvsH9w3tSGZeAcvismHs22bxrnUv1salhBDiori4OHr16vW7n/79+zu6Wn9QmWGLC4AhgI9SKg14FnAF0Fp/CHyPGbJ4EDNscWZtVXZIF18i2rTgww3J3PTINTj3mwW/fASRkyG4b21dVghhY1przIjn+iEyMpLY2Fi7XrM624NWZpTLVK11G621q9Y6SGv9idb6Q2uYYx3d8oDWuqPWOlJrXfmO8SpSSvHA0E4cOnaGVfFHzazRFm3hm/uh8GxtXVYIYUPu7u7k5uZWK7AaC601ubm5uLu7V+lzdXrqf1lGdw8g1KcZ768/yHXdr0aNfx8+nwCrnjLdMEKIOi0oKIi0tDSqMtKtMXJ3dycoKKhKn6l3ge7spLh3SEf+smQP6/dnMyxsKFz5IGx5BzoOh4hxjq6iEKICrq6udOjQwdHVaJDq5fz5ib0DCWntwVtrDph/tg37K7TtDcvnQF6ao6snhBAOUS8D3dXZidnDOrEnLY91+7LBxQ1u+gRKimDpLCgpdnQVhRDC7uploEMZrXTvjnDD65CyGX60zawrIYSoT+ptoLs6OzFnWCfi0vNYm5htDvaaCgPuh+0fQMw8h9ZPCCHsrd4GOphWejtvD/75436KSyzm4MgXzcPRFY/C4U2OraAQQthRvQ50F2cnnhwdxr6j+SzYYV0fzNkFJs2FVh1g0W1w/FfHVlIIIeykXgc6mHHpA0Jb8/qP+zl5ttAcbOoF0xaBtsCCqbLeixCiUaj3ga6U4tmx3Th1rog3Vyf99oZ3R7h5HhxLgqX3gKXEYXUUQgh7qPeBDhDepgW39m/H/7ansv9o/m9vdBwK170KSSth7fOOq6AQQthBgwh0gEdGdqF5Exee/zb+92tE9LsHou6CzW9D7ALHVVAIIWpZgwn0Vs3ceOzaLmxJzuWb2EuWY7/uVWg/yGwwfeQXx1RQCCFqWYMJdIBp/dvRO8SL57+N59jp87+94ewKkz+DFoGwcBqcPFL+SYQQop5qUIHu7KR47aYenDlfwvPfJvz+TY/WZuRL8XlYOBUKzzimkkIIUUsaVKADdPb3ZPawTny7O4M1CVm/f9O3qxmjnhUPX/8JLBbHVFIIIWpBgwt0gHuv6UhXf0+eWbaXUwVFv3+z80i49u+Q+C1seNkxFRRCiFpQqUBXSo1WSu1XSh1USj1ZxvvtlFJrlVJ7lFIblFJVW5XdxtxcnHh1Ug+y8wt45Yd9fyww4H7oPR02vgZ7v7J/BYUQohZcNtCVUs7A+8B1QAQwVSkVcUmxfwKfaa17AC8ADm/69gr24q6rO/DF9lQ2HTj2+zeVghvegJCBsOx+SN/pmEoKIYQNVaaF3g84qLU+pLUuBBYC4y8pEwGstf6+voz3HeKRkV3p6NuMx5fsJu/sJV0vLk1g8ufQzM+MfDmV6ZhKCiGEjVQm0AOB0uP80qzHStsN3GT9fSLgqZTyvvRESqlZSqlopVS0PfYTbOrmzJu39CIn/zx/W773jwWa+8LUBWatl4XToOhcrddJCCFqS2UCXZVx7NLtuh8DrlFK7QKuAdKBP2wbpLX+SGsdpbWO8vX1rXJlq6NHkBcPDu/MN7EZfLs7448FArrDTR9Dxi745gGQnciFEPVUZQI9DQgu9ToI+F0yaq0ztNY3aq17A09bj+XZrJY1dP+QjvQK9uKZZXs5mlfwxwJh18Pwv5kHpD//0/4VFEIIG6hMoO8AOiulOiil3IApwPLSBZRSPkqpC+d6Cphr22rWjIuzE29M7sn54hL+8tWe36/1csHVf4bIybDOOqRRCCHqmcsGuta6GJgNrAISgcVa63il1AtKqXHWYkOA/UqpJMAfeKmW6lttob7NefqGCDYm5fD5tpQ/FlAKxr0LgX3MRtOZe+xfSSGEqAFVZmvVDqKionR0dLRdr6m15o5Pd7DtUC7LZ19N1wDPPxbKPwr/GQYomLUemvvZtY5CCFERpVSM1jqqrPca5EzR8iil+OfNPfF0d2XOgp2cKyxj0wvPAJjyBZzNhUXTzdovQghRDzSqQAfw9WzCG5N7kpR1mhdXJJRdqG0vmPgBHNkO3z4sI1+EEPVCowt0gMFdfLn3mo58sT2VFXvKmVDUbSIMeQp2fwFb3rVvBYUQohoaZaADPHptF3oFe/Hk0j0cOX627EKD/wIRE2D13yBplX0rKIQQVdRoA93V2Yl3p/YGDQ8t3EVRSRlL6To5wYQPoE0PWHIXZCfav6JCCFFJjTbQAYJbe/D/boxkZ+pJ3lydVHYhNw+YssD8uWAKnMm1byWFEKKSGnWgA4zt2ZYpfYP54KdkNh88VnahloFm5MupTFg8A4oL7VtJIYSohEYf6ADPju1GR9/mPLwo9vd7kZYWFAXj34OUTfD9ozLyRQhR50igY1ZlfG9ab/LOFfHwwlhKLOWEdY/JMOgx2PkZrH3BvpUUQojLkEC3CgtowQvjurHp4DHeXlNOfzrAsGcg6k7Y9Ab8/Lr9KiiEEJfh4ugK1CW39A0mJuUE76w7SO+QVgwNK2Pav1Jw/etw/rRppbt5Qv9Z9q+sEEJcQlropSileHFCdyLatOChhbtIzS1nfPqF4YxhY+CHx2HXfPtWVAghyiCBfgl3V2c+nN4HpRR/+l9M2eu9ADi7wKS5EDoUls+G+GX2ragQQlxCAr0MId4evDWlF/uOnuL/vo4re/10MPuSTpkPQf3gq7sh6Uf7VlQIIUqRQC/H0K5+/HlEF77elc5nW8tYP/0Ct2Zw62Lwj4DFt8HhTfarpBBClCKBXoHZQzsxItyPF79LYEt5k44A3FvC9K+hVXv44hZIi7FbHYUQ4gIJ9Ao4OSnevKUXHXyacd/8nfx67Ez5hZt5w23LoJkP/O9GyIq3X0WFEAIJ9MvydHflk9v74qTgrv/uIO9cUfmFW7SBGd+Aqwd8NgGOHbRfRYUQjV6lAl0pNVoptV8pdVAp9WQZ74copdYrpXYppfYopa63fVUdJ8Tbgw+m9yE19yyzv9hJcVkrM17Qqr0JdW2Bz8ZJqAsh7Oayga6UcgbeB64DIoCpSqmIS4o9g9k8ujcwBfiXrSvqaANCvfn7hO78fOAYf19xmWV0fbvAjGVm+7pPr5PuFyGEXVSmhd4POKi1PqS1LgQWAuMvKaOBFtbfWwIZtqti3TGlXwh3XtWBeVsO8/m2Cka+AAREwswfwMkFPr0e0uy7IbYQovGpTKAHAkdKvU6zHivtOWC6UioN+B6YU9aJlFKzlFLRSqnonJycalTX8Z6+IZxhYX48+81efow/WnFh3y5w5w/Q1Avm3QBxS+xTSSFEo1SZQFdlHLt0ps1UYJ7WOgi4HvhcKfWHc2utP9JaR2mto3x9fate2zrA2Unx3rTeRAZ5MWfBLmJSjlf8gVbt4e610PYK+Oous/6LpYI+eCGEqKbKBHoaEFzqdRB/7FK5C1gMoLXeCrgDPraoYF3k4ebC3NujaOvVlDvnRXMwO7/iDzTzMQ9Kr5hhVmj86k7Tvy6EEDZUmUDfAXRWSnVQSrlhHnouv6RMKjAcQCkVjgn0+tmnUknezZvw2Z39cHV2YsYnv5S/0fQFLm4w9h0Y8TzEfw2f3wjnTtqnskKIRuGyga61LgZmA6uARMxolnil1AtKqXHWYo8C9yildgMLgDt0uQugNBzBrT347519OVNYwrSPt5Fx8lzFH1AKrn4YbvwYjmyHuaMhL80+lRVCNHjKUbkbFRWlo6MbxsiPPWknufU/2/HxbMLCWQPwb+F++Q8d2gALp0MTT5i2CNr0qPV6CiHqP6VUjNY6qqz3ZKaoDfQI8mLenf3IPlXAtP9sIye/Ev3joUPMCBiAT66VETBCiBqTQLeRPu1a8enMfmScLGD6x9s5fqbw8h8KiIRZG6BNTzMCZvXfwFLO+utCCHEZEug21K9Daz65PYrDuWeY/vF2Tp6tRKh7+sPt35p9Sje/DV9MhoJTtV9ZIUSDI4FuY1d28uE/M6I4mH2a2z75pXItdRc3GPOm+Tm0wXTB5CbXel2FEA2LBHotGNzFl3/f1oekrHwm/3srmXmXGf1yQdSdMP0rOH0UPhoC+1bUaj2FEA2LBHotGRrmx3/v7MfRvAImfbC14rXUSwsdAn/aCN4dYeE0WP0slBTXZlWFEA2EBHotGhDqzYJ7BnCuqISbP9xCXFpe5T7oFQJ3roI+M2HzW/D5BDidXbuVFULUexLotSwyqCWL/zSQJi7OTP73VlbuvcyCXhe4NIGxb8GEDyBtB/x7MKRsrd3KCiHqNQl0O+jk15xlD1xF1wBP7v1fDB9sSKbSE7p6TTOLe7k2NSs2bnkXGv4kXCFENUig24mvdRbpmB5teHXlPv6yZA+FxZVcdTGguxmvHnYD/PgMLJou68AIIf5AAt2O3F2deWdKbx4c3pkvY9K47ZPtnKjMsEYA95Yw+TMY/QokrYSProG0mNqtsBCiXpFAtzMnJ8UjI7vw1i292JV6khs/2MKhnNOV+7BSMOA+sxNSSTF8MgLWPAdFBbVaZyFE/SCB7iATegfyxT39OXWuiAnvb2b9viqMYgnuB/dvgd7TYdOb0loXQgAS6A4V1b41yx64iqBWHsyct4M3VidRYqnkA0/3ljDuXTMR6Xy+aa2vflY2zhCiEZNAd7Dg1h4svf9KJvUJ4p21B5g5b0fl+9UBOo2A+7ea1vrmt+A/wyEjtvYqLISosyTQ6wB3V2f+MakH/29iJNuScxnz7ib2pFVhFMuF1vrUhZCfYbpgvrpbJiMJ0chIoNcRSimm9Q/hy3sHAjDpg618sT218uPVAbpeB3N2wqBHIeEbeK8v7Jov49aFaCQqFehKqdFKqf1KqYNKqSfLeP9NpVSs9SdJKSWDpKupZ7AX3865mv6hrfm/r+N4cGEspwqKKn+Cpl4w/G9w72bwi4Bv7ocvb4czx2qv0kKIOuGyW9AppZyBJGAkkIbZNHqq1jqhnPJzgN5a6zsrOm9D2oKuNpRYNB/+lMwbq5No6+XOu1OvoFewV9VOYrHAlndg3d/NVnfX/t3MPFWqdiothKh1Nd2Crh9wUGt9SGtdCCwExldQfipmo2hRA85OigeGdmLxnwZgscCkD7bw4U/JWCo7CgbAyclsSn3vz+DT2bTWP70essr8u1gIUc9VJtADgSOlXqdZj/2BUqod0AFYV877s5RS0Uqp6JycnKrWtVHq06413z84iJER/rzywz5mzP2FjJOVXF/9Ar9wmLkSxr4DOYnw4dWw6mkz3FEI0WBUJtDL+vd5ec3EKcASrXWZG2NqrT/SWkdpraN8fX0rW8dGr6WHK/+69QpevjGSnaknGPXmRpbEpFXtgamTE/S53Tw07T0dtr4H7/WDvUvloakQDURlAj0NCC71OgjIKKfsFKS7pVYopZjaL4SVDw0mvE0LHvtyN7M+jyEnv4oTiTxaw7h34K410MwblsyEzyfCsYO1U3EhhN1UJtB3AJ2VUh2UUm6Y0F5+aSGlVFegFSCLdteiEG8PFswawNPXh/NTUg6j3trID3GZVT9RcF+4ZwNc9xqkx8AHA2Hti9INI0Q9dtlA11oXA7OBVUAisFhrHa+UekEpNa5U0anAQl2lfgBRHc5OinsGh7JiztUEejXlvvk7mbNgF8dOV7G17uwC/f8Es6Oh20T4+Z/wVg/Y9gGUVGGopBCiTrjssMXaIsMWbaOoxMIHG5J5d90BmjVx4ZkbIrjpikBUdYYmpsXAuhfg0AbwDYPrXjV7nAoh6oyaDlsUdZirsxMPDu/M9w8OoqNvcx77cje3ffILqblnq36yoD5w2zKYsgCKC+Cz8WYzjRMptq+4EMLmpIXegFgsmvnbU3h15X6KLRYeGdmFO6/qgItzNf7eLiowI2F+fh20Ba58EK6cbdaNEUI4TEUtdAn0Bigz7xx/XRbPmsQsurVtwUsTI6s+y/SCvHRY/VfY+5UJ8wEPwIB7JdiFcBAJ9EZIa80Pe4/y3PJ4ck6fZ3KfYB4f3RWf5k2qd8LM3fDTa7DvOxPmA2ebB6oS7ELYlQR6I5ZfUMQ7aw/w6ebDNHV15qERnZkxsD1uLtV8fJK5Gza8CvtXlAr2e8G9hW0rLoQokwS6IDnnNC9+l8CG/TmE+jbjr2MiGNrVr/onzIg1Lfb9K8Ddq1SLXYJdiNokgS4uWrcvixe/S+TXY2cYHubHM2Mi6ODTrPonzIiFn16F/d+bYL9yNvSTYBeitkigi98pLLbw6eZfeXfdQc4Xl3Dn1R14YGgnWri7Vv+kGbtMV0zSDxLsQtQiCXRRpuz8Al5buZ8lMWl4ebgye2gnpg9oh7urc/VPmrELNrwCSSuhaSvTFdNvlgS7EDYigS4qtDc9j1dX7uPnA8cI9GrKIyO7MKF3IM5ONdgII32nCfYDq0yw95kJUXeCV/DlPyuEKJcEuqiUTQeO8erKfcSl59HV35MnruvK0K5+1VtG4IL0GNj4uumKAQgfC1c9DIFX2KbSQjQyEuii0iwWzYq4TP75435Scs/Sr31rHrm2CwNCvWt24pOpsOMTiJ4L509B+0FmN6WOw2VLPCGqQAJdVFlhsYWFO1J5d91BcvLPc1Unbx4Z2YU+7VrX7MQFpyBmHmz7F+Rngn8kXPWQWe3R2cUmdReiIZNAF9VWUFTC/7al8OFPyRw7XcjgLr7MGdaJvu1rGOzF5yHuS9j8NhxLAq8QGDjH7Kbk5mGbygvRAEmgixo7W1jMZ1tT+M/GQ+SeKaRf+9Y8MKwTgzv71KyP3WIxI2I2vwVHtkPT1maCUt97zI5KQojfkUAXNnOusISFO1L5aOMhMvMKiAxsyQNDO3FthD9ONRkVA5C6DTa9ZR6gunpA79tg4APQqp1tKi9EAyCBLmyusNjC0p1pfPBTMim5Z+ns15z7h3ZkbI+21Vuut7TsRNjyLuxZZJbu7XwtXDEDOo+SfnbR6Emgi1pTXGJhRVwm/1qfzP6sfEJae3DvNR25qU8gTVxqMEEJzNK9Oz6G2C/g9FFoHgC9bzUt99YdbPMFhKhnahzoSqnRwNuAM/Cx1vqVMspMBp4DNLBbaz2tonNKoDcsFotm7b5s3lt/kN1HTuLfogn3DAplWv8QPNxq2KouKTYTlGL+CwdXm1Z71+th0KMQ2EeGPYpGpUaBrpRyBpKAkUAasAOYqrVOKFWmM7AYGKa1PqGU8tNaZ1d0Xgn0hklrzeaDuby3/gDbDh2nlYcr0we047aB7fDzdK/5BfLSYed/YfuHUJAH/t2h51SIvBk8/Wt+fiHquJoG+kDgOa31KOvrpwC01i+XKvMakKS1/riylZJAb/hiUo7z4U+HWJOYhauTExN6t+Wuq0PpGuBZ85MXnDLDHnf9DzJ2gnKC0KHQc4ppvTdpXvNrCFEH1TTQJwGjtdZ3W1/fBvTXWs8uVWYZphV/FaZb5jmt9coyzjULmAUQEhLSJyVFNh9uDA7lnGbu5l9ZEpNGQZGFwV18uWdQB67uVMMhjxfkJMGehbBnMeQdAZem0GUUdL/JPFB1tcG/DISoI2oa6DcDoy4J9H5a6zmlynwHFAGTgSDgZ6C71vpkeeeVFnrjc+JMIfO3pzBvSwrHTp+ns19zZlzZnht7B9KsiQ1Gr1gskLoV4pdC/DI4e8yMa+99q1kczLtjza8hhIPZo8vlQ2Cb1nqe9fVa4Emt9Y7yziuB3nidLy7h292ZzNvyK3vTT+Hp7sItUcHMGNieEG8bzRItKYZffzLLDOxbAboEIibAlQ+ahcHkQaqop2oa6C6Y7pThQDrmoeg0rXV8qTKjMQ9Kb1dK+QC7gF5a69zyziuBLrTW7Ew9waebD7Ny71FKtGZ4mHy0X+IAABV5SURBVB93XNmBqzp526Y7BuBUJuz4D2z/CArzwTfMLDHQcyo087HNNYSwE1sMW7weeAvTPz5Xa/2SUuoFIFprvVyZ//NeB0YDJcBLWuuFFZ1TAl2UdjSvgPnbU/hieyq5ZwpNd8zAdkzoHYhnTXZSKq0gD/Yuhdj5kLYDnFyh63Vm0lLHYeBUw3HzQtiBTCwS9UZBUQkr9mQyb8th4tLzaObmzPjegdzaP4RubVva7kLZiWaEzO4FcDYXWgRahz9OAr9w211HCBuTQBf1jtaa3Wl5zN+WwvLdGZwvttAr2IvpA9oxpkebmm2TV1pxodngetfnkLzOTFryDYfuN0K3G8Gnk22uI4SNSKCLei3vbBFf7Uxj/vYUknPO0LKpKzddEcStA0Lo6GvD8eb5WZC43HTLpG4FNAREmj1Re0wBFzfbXUuIapJAFw2C1ppth44zf3sKq+KPUlSiGRjqzbT+IVzbzb/ma8eUdirDDH3c/QUcjYMmLaHTcNPn3mkEeNRwPXghqkkCXTQ4OfnnWRx9hC+2p5J+8hxeHq5M6BXI5KhgItq2sN2FtIZD602rPWkVnMkG5ybmQerVf4aWgba7lhCVIIEuGqwSi2bzwWMsjj7Cj/FZFJZY6B7Ygpv7BDO+V1u8PGzYTWKxQMYuiPnUPExVThA52TxIbT9IlvYVdiGBLhqFE2cKWRabzpfRaSRknsLN2YmR3fy5uU8Qgzr74lzTDTh+d7EU2PQmxC0xY9ub+Zp9UbvfBEH9wKmGa8ILUQ4JdNHoxGfk8WV0Gsti0zl5tgj/Fk0Y3yuQib0DCW9jwy6ZonNwYDXsXWK6ZIoLoGWwGQLZbxY097XdtYRAAl00YueLS1ibmM3Snels2J9NsUUTFuDJjVcEMr5XIP4tbLhw1/l82Pe9WQXy4BpwdoVOI03LvetoaGKDVSZFoyeBLgSQe/o83+3JZOmudHYfOYmTgqs6+TCxdyCjugXYZoGwC44dgB2fQMIyyM80s1LbXWlWf+x8Lfh0lvVkRLVIoAtxieSc0yzblc7Xu9JJO3EODzdnRncLYOIVgVzZ0cd2/e0WCxzZbja+TvoRchLN8dYdTX975CTw7Wqba4lGQQJdiHJYLJrolBMs3ZnGirhM8guK8fNswriebRnbsy09glrabpEwgJOpcOBHSFgOh382M1MDIqH7JBPwXsG2u5ZokCTQhaiEgiLT374s1vS3F5VoQlp7cEOPNozp0YaINi1sG+75RyH+azNSJt36/0LIQBPs3SbKSpCiTBLoQlTRybOF/Bifxbd7MtiSnEuJRRPq04wxPdpwQ4+2ttlGr7Tjh2DvVxD3lemWUc4Q3N/svHTFDJmZKi6SQBeiBo6fKWTl3qN8tyeDbYdysWjo7NecMT3aMqZnG9uuJwOQFW/C/eBayIwFF3ez3EDYDeaBqrTcGzUJdCFsJDu/wIT77kx2pBxHawhv04Ix1m6Zdt7NbHvBrAQzM3XfCjiVbo61DjXDIXtMhqAy/78WDZgEuhC14GheAd/HZfLdngx2pprtcyMDW1q7ZdoQ1MpG2+mBWVMmMxYO/QQpW8z2esUF0LY39JwGEePB09921xN1lgS6ELUs/eQ5vt9jwn13Wh4AvYK9LoZ7m5ZNbXvB8/kQuwB2fgZZceDkYh6k9pwKHQabSU2iQbLFFnSjgbcxW9B9rLV+5ZL37wD+gdlzFOA9rfXHFZ1TAl00VKm5Z/kuLoMVezKJzzgFQN/2rRjVLYBrIwJstxH2BVkJZvelnZ+ZdWWatobwMSbg2w+WRcMamJpuEu2M2SR6JJCG2SR6qtY6oVSZO4AorfXsylZKAl00BodyTrNiTyYr4jLZdzQfgK7+nozq5s/Ynm3p7G/D0TJF58yD1IRlsP8HKDz9W7iHjzczVd1s/JeJsLuaBvpA4Dmt9Sjr66cAtNYvlypzBxLoQlQoNfcsqxOzWJ1wlF9+PY5Fm3Af3T2A6yID6Orvabtx7mWFu7Ob6Y4JGwNdr5c+93qqpoE+CRittb7b+vo2oH/p8LYG+stADqY1/2et9ZEyzjULmAUQEhLSJyUlpVpfSIj6Lju/gO/3ZPJ93NGLo2U6+DTj2m7+XBsRQO9gL5xstfxA0Tk4vNls1LHvOzhxGFAQeAV0HmWWH/DuaJtriVpX00C/GRh1SaD301rPKVXGGzittT6vlLoXmKy1HlbReaWFLoSRk3+eHxOOsnLvUbYm51Js0fg0b8Kobv6M7h7AgFBvXJ1ttL661pCdaIL9wGpI2wFoM1qm243QbQJ4hdjmWqJW1HqXyyXlnYHjWuuWFZ1XAl2IP8o7V8SG/dn8GJ/F+v3ZnC0soWVTV4aF+TEywp/BXXxpbstVIU9lmKUH4pea3ZgAgvqaB6oR46FlkO2uJWyipoHugulGGY4ZxbIDmKa1ji9Vpo3WOtP6+0TgCa31gIrOK4EuRMUKikrYmJTDyvijrNuXzcmzRbg5O3FlJ29GRvgzMtwfP1uu5378V7O2TPzXcHSPORY8wHTJhI+TPvc6whbDFq8H3sIMW5yrtX5JKfUCEK21Xq6UehkYBxQDx4H7tNb7KjqnBLoQlVdcYiE65QSrE7JYnZBF6vGzAPQM9uLaCH9GRvjT2a+57R6q5iabVvvepZCdACgzSiZiPISPhRZtbXMdUWUysUiIBkRrTVLWaVYnHGV1QtbFiUztvD0YGW7CvU+7VrjYqt89KwESvjE/F9ZzD+5vWu0R46TP3c4k0IVowI7mFbAm0bTctybnUlhioZWHK0PD/LjW2u/u4WajfvecJEi0hvvROHOs7RWm5R45Sfrc7UACXYhG4vT5YjYm5bA6IYt1+7LJO1eEm4sTV3fyYWSEP8PD/fDztFG/e24yJC434Z6xC1DQ/mrocYtpubtXOC5CVJMEuhCNUFGJhR2Hj1/sd087cQ6lzBozIyP8uTbCn46+Nup3P34I9nwJexaa353dzIqQ3W+ErteBm41XoWzEJNCFaOS01uw7mn8x3OPSTb97qE8zRnbzZ1S3AHoF2WAyk9aQHmPWc9+7FE4fBZemJtSvmGEerLo0scE3arwk0IUQv5OZd441CVn8aO13L7ZofD2bMCLcjxHh/lzVyQd3V+eaXcRSAqlbTbDv/QoKToJrM7O2TM+p0OEacLLRg9tGRAJdCFGuvLNFrNufxZrEbH7an8Pp88W4uzpxdSdfRkb4MSzMH1/PGraqC8/CoQ2Q9IPpcy/IA6925kFql+vMMgRONfwLpJGQQBdCVEphsYXtv+ayJsEEfPpJ0+/eO9iLkREBXNvNv+Zb7hUVQOK3sOszs8aMLgEPH7PNXseh5sGqjJYplwS6EKLKyut37+jbjBHWmaq9Q1rhXJN+97PHIXkdJK00q0OeO26OB0aZdWUiJoBXsA2+TcMhgS6EqLH0kxf63Y+y/dBxii2a1s3cGNrVj5ERfgzq7EuzmqwzY7GYWakHfjTL/mbuNsdlbZnfkUAXQtjUqYIiftqfw9pEM979VEExbs5ODOzozYgIf0aE+9V8273cZNPfXnptmTY9oeNwiLwZ/CNq/kXqIQl0IUStKSqxEH34BGsTs1idmEVKrllnplvbFoywLkXQrW2Lmo13z002rfaDayF1m+l3D4g0LfeOwyGgR6MZMSOBLoSwC601yTmnWZOYzZqELGJST6A1BLRwZ3i4HyMi/BkY6l2zIZGnc8wwyD2LIGOnOdYi0LTao+6EVu1s82XqKAl0IYRD5J4+z/r9OaxJyGLjgRzOFpbg4ebMoM4+DA/3Z1iYHz7NazAkMj8LktearpkDqwENoUOhx2QIuwGa2HDP1jpCAl0I4XAFRSVsO5TLmsQs1iZmk5lXgFJwRUgrhof7MTLcn041WQI4Lw2i55olCPJSrTNUR5s9VDsNh6atbPuFHEQCXQhRp2itic84dTHcLwyJbOftwfAwf0ZE+NG3fevqbb1nscCR7bB3CcQvg7PHQDmbJX+7XGsmMvmF2fgb2Y8EuhCiTsvMO8faxGzWJmaxOTmXwmILLdxdGNLV9Ltf08WXlk1dq35iS4lZWyZpFRxY9duSv4F9oM8dZk33pl42/S61TQJdCFFvnDlfzM8Hjl0cEpl7phAXJ0W/Dq0ZEe7PiHB/Qrw9qnfyUxmm1R4zD47tBydXMzs1Yrzpc68H3TIS6EKIeqnEook9cuLiqJkD2acB6OLf3IR7hH/1VonUGtJ3QsLXEP+N6XN3coHQIWZ2atgN4NHa5t/HFmyxp+ho4G3MnqIfa61fKafcJOBLoK/WusK0lkAXQlRVSu6Zi+H+y+HjlFg0Ps3dGBbmx/BwfwZ19qn67kxam+GP8cvMWPeT1nDvMNiEe/jYOhXuNQp0pZQzkASMBNKAHcBUrXXCJeU8gRWAGzBbAl0IUZvyzhaxISmbNYnZbNifTX5B8cXdmYZblwH2b1HF3Zm0NrsvJXxjwv3EYfNAtcNgs1lH+FiHd8vUNNAHAs9prUdZXz8FoLV++ZJybwFrgMeAxyTQhRD2UlRiYcevx1mdmMWaxCyOHD8HQI+glhdHzUS0qeJsVa3NejIJy0zr/cSvv+3EFHkTdBntkJ2Yahrok4DRWuu7ra9vA/prrWeXKtMbeEZrfZNSagPlBLpSahYwCyAkJKRPSkpKNb+SEEKUTWvNgezTrE7IYm1iFruOnERraNvSneHWfvcBoa1p4lKF2aoXumXivoL4pZCfaca5dxpuHqh2GWW3PVRrGug3A6MuCfR+Wus51tdOwDrgDq314YoCvTRpoQsh7CEn/zzr92WzJjGLnw8c41xRCc3cnBncxZcR4f4MDfOjdTO3yp/QUgIpW8wG2YnfmnB3cjUPVMPHmgeqzXxq6+vUbpeLUqolkAyctn4kADgOjKso1CXQhRD2VlBUwpbkY6yxjnnPOnUeJwV92rW6OGqmSht4WCyQHm3CPWE5nEwB5QTtrvptyV8bh3tNA90F81B0OJCOeSg6TWsdX075DUgLXQhRx1ksmr0ZeRdHzSRkngKgg0+zi3ur9mnXCpfKzlbV2kxcSlxu+txzD5hwDxlolh8Iu8EmC4fZYtji9cBbmGGLc7XWLymlXgCitdbLLym7AQl0IUQ9k37yHOsSs1idmM225FwKSyx4ebgytKsJ98FdfPB0r+RsVa0ha69pte9bAdnW9m9ApJmd2m0i+HSuVj1lYpEQQlTB6fPF/JyUw+rELNbvy+bE2SJcnRUDQr0ZEe7P8HA/glpVYbZqbjLs/x4SvzPrzKDBv7sZ595tQpXCXQJdCCGqqcSi2Zl6wrpxdhbJOWcACAvwZGSEP8PD/ekR2LLys1VPZZiWe/zXcGSbOebf3Yxz7zEFWgZW+HEJdCGEsJFDOadZm2hGzew4fByLBl/PJowI92N4mD9XdfKhqVslh0TmpZs+971LIe0Xcyy4v+mWCR9bZp+7BLoQQtSCE2cKL85W/Wl/DqfPF+Puamarjgj3Z1i4H36elZytmptsgj3xm99WhWzTCyLGQfh48OkESKALIUStKyy2sP3XXNYmZrM6IYv0k2a2as9gL0Zat9/r6u9Zudmqxw+ZbpnE5Wb5XwC/CIgYjxr6lAS6EELYi9aa/Vn5rEkwo2Z2HzkJQKBXU0ZGmCWA+3VojZtLJYZE5qWZCUwJyyF1K+r5PAl0IYRwlOxTBayzzlbddPAYBUUWPJu4MLirLyPD/RnS1Rcvj0rMVs3PQrUIkEAXQoi64FxhCZsPHjPb7+3LJif/PM5Oiqh2rS6OmungU/6iX9KHLoQQdZDFotmTnndxSOS+o/kAdPRtxghr18wVIa1wLjUkUgJdCCHqgSPHz7LW2nLfdiiXohJN62ZuDLF2zQzq4ounu2u5gV7FrT2EEELUluDWHtxxVQfuuKoDpwqK2JiUY908O5ulO9Nxu8y6MhLoQghRB7Vwd2VMj7aM6dGW4hILMSknWJOYxTMVfEYCXQgh6jgXZyf6h3rTP9S7wkCv5LqQQggh6joJdCGEaCAk0IUQooGQQBdCiAZCAl0IIRoICXQhhGggJNCFEKKBkEAXQogGwmFruSil8oH9Drl43eMDHHN0JeoIuRe/kXvxe3I/jHZaa9+y3nDkTNH95S0w09gopaLlXhhyL34j9+L35H5cnnS5CCFEAyGBLoQQDYQjA/0jB167rpF78Ru5F7+Re/F7cj8uw2EPRYUQQtiWdLkIIUQDIYEuhBANhEMCXSk1Wim1Xyl1UCn1pCPqYE9KqblKqWyl1N5Sx1orpVYrpQ5Y/2xlPa6UUu9Y780epdQVjqu57SmlgpVS65VSiUqpeKXUQ9bjje5+KKXclVK/KKV2W+/F89bjHZRS2633YpFSys16vIn19UHr++0dWf/aoJRyVkrtUkp9Z33daO9Fddg90JVSzsD7wHVABDBVKRVh73rY2Txg9CXHngTWaq07A2utr8Hcl87Wn1nAB3aqo70UA49qrcOBAcAD1v/+jfF+nAeGaa17Ar2A0UqpAcCrwJvWe3ECuMta/i7ghNa6E/CmtVxD8xCQWOp1Y74XVae1tusPMBBYVer1U8BT9q6HA753e2Bvqdf7gTbW39tgJloB/BuYWla5hvgDfAOMbOz3A/AAdgL9MbMhXazHL/7/AqwCBlp/d7GWU46uuw3vQRDmL/NhwHeAaqz3oro/juhyCQSOlHqdZj3W2PhrrTMBrH/6WY83mvtj/Wdyb2A7jfR+WLsYYoFsYDWQDJzUWhdbi5T+vhfvhfX9PMDbvjWuVW8BfwEs1tfeNN57US2OCHRVxjEZO/mbRnF/lFLNga+Ah7XWpyoqWsaxBnM/tNYlWutemNZpPyC8rGLWPxvsvVBKjQGytdYxpQ+XUbTB34uacESgpwHBpV4HARkOqIejZSml2gBY/8y2Hm/w90cp5YoJ8/la66XWw432fgBorU8CGzDPFbyUUhfWWSr9fS/eC+v7LYHj9q1prbkKGKeUOgwsxHS7vEXjvBfV5ohA3wF0tj69dgOmAMsdUA9HWw7cbv39dkxf8oXjM6yjOwYAeRe6IhoCpZQCPgEStdZvlHqr0d0PpZSvUsrL+ntTYATmgeB6YJK12KX34sI9mgSs09ZO5PpOa/2U1jpIa90ekwnrtNa30gjvRY046OHH9UASpr/waUc/SLDD910AZAJFmJbFXZj+vrXAAeufra1lFWYUUDIQB0Q5uv42vhdXY/5pvAeItf5c3xjvB9AD2GW9F3uBv1mPhwK/AAeBL4Em1uPu1tcHre+HOvo71NJ9GQJ8J/ei6j8y9V8IIRoImSkqhBANhAS6EEI0EBLoQgjRQEigCyFEAyGBLoQQDYQEuhBCNBAS6EII0UD8f4J6vEiahr2xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cf53a41c08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.360436350107193, 1.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/500\n",
      "150/150 [==============================] - 1s 7ms/sample - loss: 1.0617 - accuracy: 0.5533\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0599 - accuracy: 0.6133\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 1.0580 - accuracy: 0.6133\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0560 - accuracy: 0.6133\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0539 - accuracy: 0.6133\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0517 - accuracy: 0.6067\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 1.0496 - accuracy: 0.6067\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0470 - accuracy: 0.6000\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 0s 131us/sample - loss: 1.0444 - accuracy: 0.6000\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 0s 168us/sample - loss: 1.0417 - accuracy: 0.6000\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0392 - accuracy: 0.6000\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0363 - accuracy: 0.6000\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0334 - accuracy: 0.6000\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 1.0302 - accuracy: 0.6000\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 1.0272 - accuracy: 0.6000\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0240 - accuracy: 0.6000\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0207 - accuracy: 0.6000\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0174 - accuracy: 0.6000\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0138 - accuracy: 0.6000\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0102 - accuracy: 0.6000\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0067 - accuracy: 0.6000\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0032 - accuracy: 0.6000\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.9994 - accuracy: 0.6000\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9954 - accuracy: 0.6000\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9917 - accuracy: 0.6000\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9879 - accuracy: 0.6000\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9843 - accuracy: 0.5933\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9807 - accuracy: 0.6067\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.9773 - accuracy: 0.6067\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9738 - accuracy: 0.6067\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.9700 - accuracy: 0.6133\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9664 - accuracy: 0.6133\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9628 - accuracy: 0.6133\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9591 - accuracy: 0.6133\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9553 - accuracy: 0.6267\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.9516 - accuracy: 0.6267\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.9477 - accuracy: 0.6267\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9439 - accuracy: 0.6267\n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9402 - accuracy: 0.6267\n",
      "Epoch 40/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9362 - accuracy: 0.6400\n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9324 - accuracy: 0.6467\n",
      "Epoch 42/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9285 - accuracy: 0.6467\n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9247 - accuracy: 0.6467\n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9210 - accuracy: 0.6467\n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9170 - accuracy: 0.6467\n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9132 - accuracy: 0.6533\n",
      "Epoch 47/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9093 - accuracy: 0.6533\n",
      "Epoch 48/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9054 - accuracy: 0.6533\n",
      "Epoch 49/500\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.9017 - accuracy: 0.6533\n",
      "Epoch 50/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.8978 - accuracy: 0.6533\n",
      "Epoch 51/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8940 - accuracy: 0.6533\n",
      "Epoch 52/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8901 - accuracy: 0.6533\n",
      "Epoch 53/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8864 - accuracy: 0.6533\n",
      "Epoch 54/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8825 - accuracy: 0.6600\n",
      "Epoch 55/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8787 - accuracy: 0.6600\n",
      "Epoch 56/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8750 - accuracy: 0.6600\n",
      "Epoch 57/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8713 - accuracy: 0.6600\n",
      "Epoch 58/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.8674 - accuracy: 0.6600\n",
      "Epoch 59/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8637 - accuracy: 0.6600\n",
      "Epoch 60/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8599 - accuracy: 0.6600\n",
      "Epoch 61/500\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.8562 - accuracy: 0.6600\n",
      "Epoch 62/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8527 - accuracy: 0.6600\n",
      "Epoch 63/500\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.8490 - accuracy: 0.6600\n",
      "Epoch 64/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8453 - accuracy: 0.6600\n",
      "Epoch 65/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8417 - accuracy: 0.6600\n",
      "Epoch 66/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8382 - accuracy: 0.6667\n",
      "Epoch 67/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8346 - accuracy: 0.6667\n",
      "Epoch 68/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.8311 - accuracy: 0.6667\n",
      "Epoch 69/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8276 - accuracy: 0.6667\n",
      "Epoch 70/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8241 - accuracy: 0.6667\n",
      "Epoch 71/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8206 - accuracy: 0.6667\n",
      "Epoch 72/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8172 - accuracy: 0.6667\n",
      "Epoch 73/500\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.8137 - accuracy: 0.6667\n",
      "Epoch 74/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8104 - accuracy: 0.6667\n",
      "Epoch 75/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.8070 - accuracy: 0.6667\n",
      "Epoch 76/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8036 - accuracy: 0.6667\n",
      "Epoch 77/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8004 - accuracy: 0.6667\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 118us/sample - loss: 0.7971 - accuracy: 0.6667\n",
      "Epoch 79/500\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.7939 - accuracy: 0.6667\n",
      "Epoch 80/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7907 - accuracy: 0.6667\n",
      "Epoch 81/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7875 - accuracy: 0.6667\n",
      "Epoch 82/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7844 - accuracy: 0.6667\n",
      "Epoch 83/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.7812 - accuracy: 0.6667\n",
      "Epoch 84/500\n",
      "150/150 [==============================] - 0s 135us/sample - loss: 0.7782 - accuracy: 0.6667\n",
      "Epoch 85/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7751 - accuracy: 0.6667\n",
      "Epoch 86/500\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.7720 - accuracy: 0.6667\n",
      "Epoch 87/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7691 - accuracy: 0.6667\n",
      "Epoch 88/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7661 - accuracy: 0.6667\n",
      "Epoch 89/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7631 - accuracy: 0.6667\n",
      "Epoch 90/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7603 - accuracy: 0.6667\n",
      "Epoch 91/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7574 - accuracy: 0.6667\n",
      "Epoch 92/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7545 - accuracy: 0.6667\n",
      "Epoch 93/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7517 - accuracy: 0.6667\n",
      "Epoch 94/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7489 - accuracy: 0.6667\n",
      "Epoch 95/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7462 - accuracy: 0.6667\n",
      "Epoch 96/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7434 - accuracy: 0.6667\n",
      "Epoch 97/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7408 - accuracy: 0.6667\n",
      "Epoch 98/500\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.7381 - accuracy: 0.6667\n",
      "Epoch 99/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7355 - accuracy: 0.6667\n",
      "Epoch 100/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7329 - accuracy: 0.6667\n",
      "Epoch 101/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7303 - accuracy: 0.6667\n",
      "Epoch 102/500\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7277 - accuracy: 0.6667\n",
      "Epoch 103/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7252 - accuracy: 0.6667\n",
      "Epoch 104/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7228 - accuracy: 0.6667\n",
      "Epoch 105/500\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.7203 - accuracy: 0.6667\n",
      "Epoch 106/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7179 - accuracy: 0.6667\n",
      "Epoch 107/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7154 - accuracy: 0.6667\n",
      "Epoch 108/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7130 - accuracy: 0.6667\n",
      "Epoch 109/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7107 - accuracy: 0.6667\n",
      "Epoch 110/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7084 - accuracy: 0.6667\n",
      "Epoch 111/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7061 - accuracy: 0.6667\n",
      "Epoch 112/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.7038 - accuracy: 0.6667\n",
      "Epoch 113/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7016 - accuracy: 0.6667\n",
      "Epoch 114/500\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.6994 - accuracy: 0.6667\n",
      "Epoch 115/500\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.6972 - accuracy: 0.6667\n",
      "Epoch 116/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.6950 - accuracy: 0.6667\n",
      "Epoch 117/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6929 - accuracy: 0.6667\n",
      "Epoch 118/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6908 - accuracy: 0.6667\n",
      "Epoch 119/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6887 - accuracy: 0.6667\n",
      "Epoch 120/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6867 - accuracy: 0.6667\n",
      "Epoch 121/500\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6846 - accuracy: 0.6667\n",
      "Epoch 122/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6826 - accuracy: 0.6667\n",
      "Epoch 123/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6807 - accuracy: 0.6667\n",
      "Epoch 124/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6787 - accuracy: 0.6667\n",
      "Epoch 125/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.6767 - accuracy: 0.6667\n",
      "Epoch 126/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6748 - accuracy: 0.6667\n",
      "Epoch 127/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6730 - accuracy: 0.6667\n",
      "Epoch 128/500\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.6711 - accuracy: 0.6667\n",
      "Epoch 129/500\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6693 - accuracy: 0.6667\n",
      "Epoch 130/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6675 - accuracy: 0.6667\n",
      "Epoch 131/500\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.6657 - accuracy: 0.6667\n",
      "Epoch 132/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6639 - accuracy: 0.6667\n",
      "Epoch 133/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6621 - accuracy: 0.6667\n",
      "Epoch 134/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6604 - accuracy: 0.6667\n",
      "Epoch 135/500\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.6587 - accuracy: 0.6667\n",
      "Epoch 136/500\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.6570 - accuracy: 0.6667\n",
      "Epoch 137/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6554 - accuracy: 0.6667\n",
      "Epoch 138/500\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.6538 - accuracy: 0.6667\n",
      "Epoch 139/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6522 - accuracy: 0.6667\n",
      "Epoch 140/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6505 - accuracy: 0.6667\n",
      "Epoch 141/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6489 - accuracy: 0.6667\n",
      "Epoch 142/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6474 - accuracy: 0.6667\n",
      "Epoch 143/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6458 - accuracy: 0.6667\n",
      "Epoch 144/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6443 - accuracy: 0.6667\n",
      "Epoch 145/500\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.6428 - accuracy: 0.6667\n",
      "Epoch 146/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6413 - accuracy: 0.6667\n",
      "Epoch 147/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6398 - accuracy: 0.6667\n",
      "Epoch 148/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6384 - accuracy: 0.6667\n",
      "Epoch 149/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6370 - accuracy: 0.6667\n",
      "Epoch 150/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6355 - accuracy: 0.6667\n",
      "Epoch 151/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6341 - accuracy: 0.6667\n",
      "Epoch 152/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6327 - accuracy: 0.6667\n",
      "Epoch 153/500\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.6313 - accuracy: 0.6667\n",
      "Epoch 154/500\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.6300 - accuracy: 0.6667\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6287 - accuracy: 0.6667\n",
      "Epoch 156/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.6273 - accuracy: 0.6667\n",
      "Epoch 157/500\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.6260 - accuracy: 0.6667\n",
      "Epoch 158/500\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.6247 - accuracy: 0.6667\n",
      "Epoch 159/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.6235 - accuracy: 0.6667\n",
      "Epoch 160/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6222 - accuracy: 0.6667\n",
      "Epoch 161/500\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.6210 - accuracy: 0.6667\n",
      "Epoch 162/500\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.6197 - accuracy: 0.6667\n",
      "Epoch 163/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6185 - accuracy: 0.6667\n",
      "Epoch 164/500\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.6173 - accuracy: 0.6667\n",
      "Epoch 165/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.6161 - accuracy: 0.6667\n",
      "Epoch 166/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6150 - accuracy: 0.6667\n",
      "Epoch 167/500\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.6137 - accuracy: 0.6667\n",
      "Epoch 168/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6126 - accuracy: 0.6667\n",
      "Epoch 169/500\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.6114 - accuracy: 0.6667\n",
      "Epoch 170/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6103 - accuracy: 0.6600\n",
      "Epoch 171/500\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.6092 - accuracy: 0.6600\n",
      "Epoch 172/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6081 - accuracy: 0.6600\n",
      "Epoch 173/500\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.6070 - accuracy: 0.6600\n",
      "Epoch 174/500\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.6059 - accuracy: 0.6600\n",
      "Epoch 175/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6049 - accuracy: 0.6600\n",
      "Epoch 176/500\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.6038 - accuracy: 0.6533\n",
      "Epoch 177/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6028 - accuracy: 0.6533\n",
      "Epoch 178/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6018 - accuracy: 0.6533\n",
      "Epoch 179/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6007 - accuracy: 0.6533\n",
      "Epoch 180/500\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5997 - accuracy: 0.6533\n",
      "Epoch 181/500\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.5987 - accuracy: 0.6533\n",
      "Epoch 182/500\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.5977 - accuracy: 0.6533\n",
      "Epoch 183/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5968 - accuracy: 0.6533\n",
      "Epoch 184/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5958 - accuracy: 0.6533\n",
      "Epoch 185/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5948 - accuracy: 0.6533\n",
      "Epoch 186/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5939 - accuracy: 0.6533\n",
      "Epoch 187/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5930 - accuracy: 0.6533\n",
      "Epoch 188/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5920 - accuracy: 0.6533\n",
      "Epoch 189/500\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.5911 - accuracy: 0.6533\n",
      "Epoch 190/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5902 - accuracy: 0.6533\n",
      "Epoch 191/500\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.5893 - accuracy: 0.6533\n",
      "Epoch 192/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5884 - accuracy: 0.6533\n",
      "Epoch 193/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5875 - accuracy: 0.6533\n",
      "Epoch 194/500\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.5867 - accuracy: 0.6533\n",
      "Epoch 195/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5858 - accuracy: 0.6533\n",
      "Epoch 196/500\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.5849 - accuracy: 0.6533\n",
      "Epoch 197/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5841 - accuracy: 0.6533\n",
      "Epoch 198/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5833 - accuracy: 0.6533\n",
      "Epoch 199/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5824 - accuracy: 0.6533\n",
      "Epoch 200/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5816 - accuracy: 0.6533\n",
      "Epoch 201/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5808 - accuracy: 0.6533\n",
      "Epoch 202/500\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5800 - accuracy: 0.6533\n",
      "Epoch 203/500\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5792 - accuracy: 0.6533\n",
      "Epoch 204/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5784 - accuracy: 0.6533\n",
      "Epoch 205/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5777 - accuracy: 0.6533\n",
      "Epoch 206/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5769 - accuracy: 0.6533\n",
      "Epoch 207/500\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5761 - accuracy: 0.6533\n",
      "Epoch 208/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5753 - accuracy: 0.6533\n",
      "Epoch 209/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5746 - accuracy: 0.6533\n",
      "Epoch 210/500\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5738 - accuracy: 0.6533\n",
      "Epoch 211/500\n",
      "150/150 [==============================] - 0s 136us/sample - loss: 0.5731 - accuracy: 0.6533\n",
      "Epoch 212/500\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5724 - accuracy: 0.6533\n",
      "Epoch 213/500\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 0.5717 - accuracy: 0.6533\n",
      "Epoch 214/500\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.5710 - accuracy: 0.6533\n",
      "Epoch 215/500\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.5703 - accuracy: 0.6533\n",
      "Epoch 216/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5695 - accuracy: 0.6533\n",
      "Epoch 217/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5688 - accuracy: 0.6533\n",
      "Epoch 218/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5681 - accuracy: 0.6533\n",
      "Epoch 219/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5675 - accuracy: 0.6533\n",
      "Epoch 220/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5668 - accuracy: 0.6533\n",
      "Epoch 221/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.5661 - accuracy: 0.6533\n",
      "Epoch 222/500\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.5654 - accuracy: 0.6533\n",
      "Epoch 223/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5649 - accuracy: 0.6533\n",
      "Epoch 224/500\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.5642 - accuracy: 0.6533\n",
      "Epoch 225/500\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.5635 - accuracy: 0.6533\n",
      "Epoch 226/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5629 - accuracy: 0.6533\n",
      "Epoch 227/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5622 - accuracy: 0.6533\n",
      "Epoch 228/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5616 - accuracy: 0.6533\n",
      "Epoch 229/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5610 - accuracy: 0.6533\n",
      "Epoch 230/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5604 - accuracy: 0.6533\n",
      "Epoch 231/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5598 - accuracy: 0.6533\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5592 - accuracy: 0.6533\n",
      "Epoch 233/500\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.5586 - accuracy: 0.6533\n",
      "Epoch 234/500\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.5580 - accuracy: 0.6533\n",
      "Epoch 235/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5574 - accuracy: 0.6533\n",
      "Epoch 236/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5568 - accuracy: 0.6533\n",
      "Epoch 237/500\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.5562 - accuracy: 0.6533\n",
      "Epoch 238/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5557 - accuracy: 0.6533\n",
      "Epoch 239/500\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.5551 - accuracy: 0.6533\n",
      "Epoch 240/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5545 - accuracy: 0.6533\n",
      "Epoch 241/500\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5540 - accuracy: 0.6533\n",
      "Epoch 242/500\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.5534 - accuracy: 0.6533\n",
      "Epoch 243/500\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.5529 - accuracy: 0.6533\n",
      "Epoch 244/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5524 - accuracy: 0.6533\n",
      "Epoch 245/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5518 - accuracy: 0.6533\n",
      "Epoch 246/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5513 - accuracy: 0.6533\n",
      "Epoch 247/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5507 - accuracy: 0.6533\n",
      "Epoch 248/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5502 - accuracy: 0.6533\n",
      "Epoch 249/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5497 - accuracy: 0.6533\n",
      "Epoch 250/500\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.5492 - accuracy: 0.6533\n",
      "Epoch 251/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5486 - accuracy: 0.6533\n",
      "Epoch 252/500\n",
      "150/150 [==============================] - 0s 135us/sample - loss: 0.5482 - accuracy: 0.6533\n",
      "Epoch 253/500\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5476 - accuracy: 0.6533\n",
      "Epoch 254/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.5471 - accuracy: 0.6533\n",
      "Epoch 255/500\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.5466 - accuracy: 0.6533\n",
      "Epoch 256/500\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.5461 - accuracy: 0.6533\n",
      "Epoch 257/500\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5456 - accuracy: 0.6533\n",
      "Epoch 258/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5452 - accuracy: 0.6533\n",
      "Epoch 259/500\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.5447 - accuracy: 0.6533\n",
      "Epoch 260/500\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5442 - accuracy: 0.6533\n",
      "Epoch 261/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5437 - accuracy: 0.6533\n",
      "Epoch 262/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5432 - accuracy: 0.6533\n",
      "Epoch 263/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5428 - accuracy: 0.6533\n",
      "Epoch 264/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5423 - accuracy: 0.6533\n",
      "Epoch 265/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5418 - accuracy: 0.6533\n",
      "Epoch 266/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5414 - accuracy: 0.6533\n",
      "Epoch 267/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5409 - accuracy: 0.6533\n",
      "Epoch 268/500\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5405 - accuracy: 0.6533\n",
      "Epoch 269/500\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5400 - accuracy: 0.6533\n",
      "Epoch 270/500\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.5396 - accuracy: 0.6533\n",
      "Epoch 271/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5392 - accuracy: 0.6533\n",
      "Epoch 272/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5387 - accuracy: 0.6533\n",
      "Epoch 273/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5383 - accuracy: 0.6533\n",
      "Epoch 274/500\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.5379 - accuracy: 0.6533\n",
      "Epoch 275/500\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.5374 - accuracy: 0.6533\n",
      "Epoch 276/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5370 - accuracy: 0.6533\n",
      "Epoch 277/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5366 - accuracy: 0.6533\n",
      "Epoch 278/500\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.5362 - accuracy: 0.6533\n",
      "Epoch 279/500\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5357 - accuracy: 0.6533\n",
      "Epoch 280/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5353 - accuracy: 0.6533\n",
      "Epoch 281/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5349 - accuracy: 0.6533\n",
      "Epoch 282/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5345 - accuracy: 0.6533\n",
      "Epoch 283/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5341 - accuracy: 0.6533\n",
      "Epoch 284/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5336 - accuracy: 0.6533\n",
      "Epoch 285/500\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5332 - accuracy: 0.6533\n",
      "Epoch 286/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5328 - accuracy: 0.6533\n",
      "Epoch 287/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5324 - accuracy: 0.6533\n",
      "Epoch 288/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5320 - accuracy: 0.6533\n",
      "Epoch 289/500\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.5315 - accuracy: 0.6533\n",
      "Epoch 290/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5311 - accuracy: 0.6533\n",
      "Epoch 291/500\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5305 - accuracy: 0.6533\n",
      "Epoch 292/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.5301 - accuracy: 0.6533\n",
      "Epoch 293/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5295 - accuracy: 0.6533\n",
      "Epoch 294/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5286 - accuracy: 0.6533\n",
      "Epoch 295/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5277 - accuracy: 0.6533\n",
      "Epoch 296/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5267 - accuracy: 0.6533\n",
      "Epoch 297/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5259 - accuracy: 0.6600\n",
      "Epoch 298/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5237 - accuracy: 0.6600\n",
      "Epoch 299/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5220 - accuracy: 0.6600\n",
      "Epoch 300/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5208 - accuracy: 0.6600\n",
      "Epoch 301/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5198 - accuracy: 0.6600\n",
      "Epoch 302/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5186 - accuracy: 0.6667\n",
      "Epoch 303/500\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.5177 - accuracy: 0.6667\n",
      "Epoch 304/500\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.5163 - accuracy: 0.6667\n",
      "Epoch 305/500\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5156 - accuracy: 0.6600\n",
      "Epoch 306/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5149 - accuracy: 0.6600\n",
      "Epoch 307/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5142 - accuracy: 0.6600\n",
      "Epoch 308/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5134 - accuracy: 0.6600\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 65us/sample - loss: 0.5127 - accuracy: 0.6533\n",
      "Epoch 310/500\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.5121 - accuracy: 0.6400\n",
      "Epoch 311/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5113 - accuracy: 0.6400\n",
      "Epoch 312/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5105 - accuracy: 0.7267\n",
      "Epoch 313/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5100 - accuracy: 0.7467\n",
      "Epoch 314/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5093 - accuracy: 0.7467\n",
      "Epoch 315/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5086 - accuracy: 0.7467\n",
      "Epoch 316/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5079 - accuracy: 0.7400\n",
      "Epoch 317/500\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.5071 - accuracy: 0.7400\n",
      "Epoch 318/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5064 - accuracy: 0.7333\n",
      "Epoch 319/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5059 - accuracy: 0.7400\n",
      "Epoch 320/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5053 - accuracy: 0.7267\n",
      "Epoch 321/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5046 - accuracy: 0.7333\n",
      "Epoch 322/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5038 - accuracy: 0.7400\n",
      "Epoch 323/500\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.5031 - accuracy: 0.7533\n",
      "Epoch 324/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5025 - accuracy: 0.7467\n",
      "Epoch 325/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5020 - accuracy: 0.7533\n",
      "Epoch 326/500\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5012 - accuracy: 0.7467\n",
      "Epoch 327/500\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.5006 - accuracy: 0.7533\n",
      "Epoch 328/500\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5000 - accuracy: 0.7533\n",
      "Epoch 329/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4993 - accuracy: 0.7467\n",
      "Epoch 330/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4986 - accuracy: 0.7467\n",
      "Epoch 331/500\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.4978 - accuracy: 0.7467\n",
      "Epoch 332/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4966 - accuracy: 0.7333\n",
      "Epoch 333/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4957 - accuracy: 0.7600\n",
      "Epoch 334/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4948 - accuracy: 0.7733\n",
      "Epoch 335/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4937 - accuracy: 0.7600\n",
      "Epoch 336/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4928 - accuracy: 0.7600\n",
      "Epoch 337/500\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.4918 - accuracy: 0.7667\n",
      "Epoch 338/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4904 - accuracy: 0.7733\n",
      "Epoch 339/500\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.4891 - accuracy: 0.7800\n",
      "Epoch 340/500\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4885 - accuracy: 0.7733\n",
      "Epoch 341/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4872 - accuracy: 0.7867\n",
      "Epoch 342/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4863 - accuracy: 0.7867\n",
      "Epoch 343/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4852 - accuracy: 0.7867\n",
      "Epoch 344/500\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 0.4842 - accuracy: 0.7800\n",
      "Epoch 345/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4836 - accuracy: 0.7867\n",
      "Epoch 346/500\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.4825 - accuracy: 0.7867\n",
      "Epoch 347/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4815 - accuracy: 0.7867\n",
      "Epoch 348/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4806 - accuracy: 0.7800\n",
      "Epoch 349/500\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.4797 - accuracy: 0.7867\n",
      "Epoch 350/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4788 - accuracy: 0.7867\n",
      "Epoch 351/500\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.4780 - accuracy: 0.7867\n",
      "Epoch 352/500\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.4770 - accuracy: 0.7933\n",
      "Epoch 353/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4762 - accuracy: 0.7867\n",
      "Epoch 354/500\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4756 - accuracy: 0.7867\n",
      "Epoch 355/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4746 - accuracy: 0.8000\n",
      "Epoch 356/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4737 - accuracy: 0.7933\n",
      "Epoch 357/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4728 - accuracy: 0.8000\n",
      "Epoch 358/500\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.4723 - accuracy: 0.8000\n",
      "Epoch 359/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4714 - accuracy: 0.8000\n",
      "Epoch 360/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4705 - accuracy: 0.8000\n",
      "Epoch 361/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4697 - accuracy: 0.8000\n",
      "Epoch 362/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4690 - accuracy: 0.8000\n",
      "Epoch 363/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4683 - accuracy: 0.8000\n",
      "Epoch 364/500\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.4672 - accuracy: 0.8000\n",
      "Epoch 365/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4664 - accuracy: 0.8000\n",
      "Epoch 366/500\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4658 - accuracy: 0.8000\n",
      "Epoch 367/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4649 - accuracy: 0.8000\n",
      "Epoch 368/500\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.4642 - accuracy: 0.8000\n",
      "Epoch 369/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4633 - accuracy: 0.8067\n",
      "Epoch 370/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4625 - accuracy: 0.8067\n",
      "Epoch 371/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4617 - accuracy: 0.8067\n",
      "Epoch 372/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4609 - accuracy: 0.8067\n",
      "Epoch 373/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4601 - accuracy: 0.8067\n",
      "Epoch 374/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4594 - accuracy: 0.8000\n",
      "Epoch 375/500\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.4588 - accuracy: 0.8000\n",
      "Epoch 376/500\n",
      "150/150 [==============================] - 0s 129us/sample - loss: 0.4578 - accuracy: 0.8000\n",
      "Epoch 377/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4570 - accuracy: 0.8000\n",
      "Epoch 378/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4562 - accuracy: 0.8067\n",
      "Epoch 379/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.4555 - accuracy: 0.8067\n",
      "Epoch 380/500\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.4548 - accuracy: 0.8067\n",
      "Epoch 381/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4539 - accuracy: 0.8067\n",
      "Epoch 382/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4530 - accuracy: 0.8067\n",
      "Epoch 383/500\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.4525 - accuracy: 0.8067\n",
      "Epoch 384/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4516 - accuracy: 0.8000\n",
      "Epoch 385/500\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.4509 - accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.4502 - accuracy: 0.8000\n",
      "Epoch 387/500\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4493 - accuracy: 0.8067\n",
      "Epoch 388/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4487 - accuracy: 0.8133\n",
      "Epoch 389/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4479 - accuracy: 0.8133\n",
      "Epoch 390/500\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.4471 - accuracy: 0.8133\n",
      "Epoch 391/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4464 - accuracy: 0.8133\n",
      "Epoch 392/500\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.4457 - accuracy: 0.8133\n",
      "Epoch 393/500\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.4449 - accuracy: 0.8200\n",
      "Epoch 394/500\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.4443 - accuracy: 0.8267\n",
      "Epoch 395/500\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4435 - accuracy: 0.8267\n",
      "Epoch 396/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4427 - accuracy: 0.8133\n",
      "Epoch 397/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4418 - accuracy: 0.8133\n",
      "Epoch 398/500\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.4409 - accuracy: 0.8067\n",
      "Epoch 399/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4402 - accuracy: 0.8067\n",
      "Epoch 400/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.4388 - accuracy: 0.8000\n",
      "Epoch 401/500\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4376 - accuracy: 0.8000\n",
      "Epoch 402/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4366 - accuracy: 0.8000\n",
      "Epoch 403/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4356 - accuracy: 0.8000\n",
      "Epoch 404/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4346 - accuracy: 0.8000\n",
      "Epoch 405/500\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.4338 - accuracy: 0.8000\n",
      "Epoch 406/500\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4327 - accuracy: 0.8000\n",
      "Epoch 407/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4319 - accuracy: 0.7933\n",
      "Epoch 408/500\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.4307 - accuracy: 0.8000\n",
      "Epoch 409/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4297 - accuracy: 0.8000\n",
      "Epoch 410/500\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.4288 - accuracy: 0.8067\n",
      "Epoch 411/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4277 - accuracy: 0.8000\n",
      "Epoch 412/500\n",
      "150/150 [==============================] - 0s 143us/sample - loss: 0.4268 - accuracy: 0.8000\n",
      "Epoch 413/500\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.4258 - accuracy: 0.8000\n",
      "Epoch 414/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.4250 - accuracy: 0.8067\n",
      "Epoch 415/500\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.4242 - accuracy: 0.8067\n",
      "Epoch 416/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4230 - accuracy: 0.8133\n",
      "Epoch 417/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4220 - accuracy: 0.8133\n",
      "Epoch 418/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4213 - accuracy: 0.8000\n",
      "Epoch 419/500\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4202 - accuracy: 0.8000\n",
      "Epoch 420/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4196 - accuracy: 0.8067\n",
      "Epoch 421/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4186 - accuracy: 0.8067\n",
      "Epoch 422/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4176 - accuracy: 0.8133\n",
      "Epoch 423/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.4166 - accuracy: 0.8200\n",
      "Epoch 424/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4157 - accuracy: 0.8133\n",
      "Epoch 425/500\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.4149 - accuracy: 0.8133\n",
      "Epoch 426/500\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.4139 - accuracy: 0.8200\n",
      "Epoch 427/500\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.4132 - accuracy: 0.8133\n",
      "Epoch 428/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4122 - accuracy: 0.8200\n",
      "Epoch 429/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4118 - accuracy: 0.8200\n",
      "Epoch 430/500\n",
      "150/150 [==============================] - 0s 131us/sample - loss: 0.4104 - accuracy: 0.8267\n",
      "Epoch 431/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.4094 - accuracy: 0.8267\n",
      "Epoch 432/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4091 - accuracy: 0.8133\n",
      "Epoch 433/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4077 - accuracy: 0.8200\n",
      "Epoch 434/500\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4070 - accuracy: 0.8267\n",
      "Epoch 435/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4060 - accuracy: 0.8267\n",
      "Epoch 436/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4051 - accuracy: 0.8267\n",
      "Epoch 437/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4043 - accuracy: 0.8267\n",
      "Epoch 438/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4035 - accuracy: 0.8267\n",
      "Epoch 439/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4026 - accuracy: 0.8267\n",
      "Epoch 440/500\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.4019 - accuracy: 0.8267\n",
      "Epoch 441/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4009 - accuracy: 0.8267\n",
      "Epoch 442/500\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.4001 - accuracy: 0.8267\n",
      "Epoch 443/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.3993 - accuracy: 0.8267\n",
      "Epoch 444/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3984 - accuracy: 0.8267\n",
      "Epoch 445/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3976 - accuracy: 0.8267\n",
      "Epoch 446/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3968 - accuracy: 0.8267\n",
      "Epoch 447/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3959 - accuracy: 0.8267\n",
      "Epoch 448/500\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.3953 - accuracy: 0.8267\n",
      "Epoch 449/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3943 - accuracy: 0.8267\n",
      "Epoch 450/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3935 - accuracy: 0.8267\n",
      "Epoch 451/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.3927 - accuracy: 0.8267\n",
      "Epoch 452/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.3918 - accuracy: 0.8267\n",
      "Epoch 453/500\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.3911 - accuracy: 0.8267\n",
      "Epoch 454/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.3902 - accuracy: 0.8267\n",
      "Epoch 455/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3896 - accuracy: 0.8267\n",
      "Epoch 456/500\n",
      "150/150 [==============================] - 0s 143us/sample - loss: 0.3887 - accuracy: 0.8267\n",
      "Epoch 457/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3878 - accuracy: 0.8267\n",
      "Epoch 458/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3870 - accuracy: 0.8267\n",
      "Epoch 459/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3863 - accuracy: 0.8267\n",
      "Epoch 460/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3855 - accuracy: 0.8267\n",
      "Epoch 461/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3847 - accuracy: 0.8267\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3839 - accuracy: 0.8267\n",
      "Epoch 463/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3831 - accuracy: 0.8267\n",
      "Epoch 464/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3824 - accuracy: 0.8267\n",
      "Epoch 465/500\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3815 - accuracy: 0.8267\n",
      "Epoch 466/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3806 - accuracy: 0.8267\n",
      "Epoch 467/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3799 - accuracy: 0.8267\n",
      "Epoch 468/500\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.3791 - accuracy: 0.8267\n",
      "Epoch 469/500\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.3782 - accuracy: 0.8267\n",
      "Epoch 470/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.3776 - accuracy: 0.8267\n",
      "Epoch 471/500\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.3767 - accuracy: 0.8267\n",
      "Epoch 472/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3759 - accuracy: 0.8267\n",
      "Epoch 473/500\n",
      "150/150 [==============================] - 0s 129us/sample - loss: 0.3752 - accuracy: 0.8267\n",
      "Epoch 474/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3744 - accuracy: 0.8267\n",
      "Epoch 475/500\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.3737 - accuracy: 0.8267\n",
      "Epoch 476/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3728 - accuracy: 0.8267\n",
      "Epoch 477/500\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3720 - accuracy: 0.8267\n",
      "Epoch 478/500\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.3713 - accuracy: 0.8267\n",
      "Epoch 479/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.3705 - accuracy: 0.8333\n",
      "Epoch 480/500\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.3697 - accuracy: 0.8333\n",
      "Epoch 481/500\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.3689 - accuracy: 0.8400\n",
      "Epoch 482/500\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.3681 - accuracy: 0.8333\n",
      "Epoch 483/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.3674 - accuracy: 0.8333\n",
      "Epoch 484/500\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.3667 - accuracy: 0.8333\n",
      "Epoch 485/500\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.3659 - accuracy: 0.8267\n",
      "Epoch 486/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3652 - accuracy: 0.8333\n",
      "Epoch 487/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3643 - accuracy: 0.8400\n",
      "Epoch 488/500\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3636 - accuracy: 0.8400\n",
      "Epoch 489/500\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.3630 - accuracy: 0.8400\n",
      "Epoch 490/500\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.3621 - accuracy: 0.8400\n",
      "Epoch 491/500\n",
      "150/150 [==============================] - 0s 155us/sample - loss: 0.3613 - accuracy: 0.8467\n",
      "Epoch 492/500\n",
      "150/150 [==============================] - 0s 158us/sample - loss: 0.3605 - accuracy: 0.8467\n",
      "Epoch 493/500\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.3598 - accuracy: 0.8467\n",
      "Epoch 494/500\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3591 - accuracy: 0.8467\n",
      "Epoch 495/500\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.3583 - accuracy: 0.8467\n",
      "Epoch 496/500\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.3576 - accuracy: 0.8467\n",
      "Epoch 497/500\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.3568 - accuracy: 0.8467\n",
      "Epoch 498/500\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3561 - accuracy: 0.8467\n",
      "Epoch 499/500\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.3552 - accuracy: 0.8467\n",
      "Epoch 500/500\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3545 - accuracy: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cf5214a688>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
